{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "081c6c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\n",
      " ['7/29/1966, nan, 999-91-3709, S99988287, X5601074X, Mrs., Celia938, Roberts511, nan, Mayert710, M, white, hispanic, F, Agawam  Massachusetts  US, 362 Pacocha Gateway Apt 1, Northborough, Massachusetts, Worcester County, 1532.0, 42.27341123, -71.63243239, 1166971.45, 13416.2, 4/20/1989, nan, 5cfda74f-b462-4c73-aa96-d90da4002f8a, 40055000.0, Chronic sinusitis (disorder), Body mass index 30+ - obesity (finding), Miscarriage in first trimester, Prediabetes, Hyperlipidemia, Nasal congestion (finding), Cough (finding), Sore throat symptom (finding), Sputum finding (finding), Muscle pain (finding), Joint pain (finding), Fever (finding)', '12/19/1965, 3/1/2020, 999-70-4989, S99948277, X2560575X, Mrs., Kala987, Prohaska837, nan, Gleason633, M, white, nonhispanic, F, Boston  Massachusetts  US, 310 Effertz Promenade, Gloucester, Massachusetts, Essex County, 1930.0, 42.63072986, -70.6443488, 1229943.52, 20003.74, 2/12/1984, nan, 3fc7077f-903c-4601-8078-a016e9b5a630, 59621000.0, Hypertension, Chronic sinusitis (disorder), Body mass index 30+ - obesity (finding), Hyperlipidemia, Prediabetes, Dyspnea (finding), Wheezing (finding), Diarrhea symptom (finding), Fever (finding), Pneumonia (disorder), Hypoxemia (disorder), Respiratory distress (finding), Acute respiratory failure (disorder), Sepsis caused by virus (disorder), Acute pulmonary embolism (disorder), Injury of heart (disorder), Heart failure (disorder), Acute respiratory distress syndrome (disorder)', '6/10/1967, nan, 999-91-1294, S99999431, X11888547X, Mr., Deon400, Mante251, nan, nan, M, white, hispanic, M, Reading  Massachusetts  US, 479 Turcotte Byway Apt 47, Beverly, Massachusetts, Essex County, nan, 42.61134382, -70.87263385, 1216308.17, 5884.4, 7/5/1980, nan, e947863a-d0d9-4943-ac51-61b92f928cfa, 162864005.0, Body mass index 30+ - obesity (finding), Prediabetes, Anemia (disorder), Drug overdose, Opioid abuse (disorder), First degree burn, Cough (finding), Sputum finding (finding), Fever (finding), Loss of taste (finding)', '12/26/1995, nan, 999-11-8772, S99919263, X76708464X, Ms., María Cristina383, Laureano185, nan, nan, nan, white, hispanic, F, Santo Domingo  National District  DO, 506 Daugherty Neck Unit 41, Hampden, Massachusetts, Hampden County, nan, 42.11948085, -72.41484443, 515342.88, 6450.27, 2/18/2014, nan, 02d68d39-2195-4b7b-8a80-0412a32a88fe, 59621000.0, Hypertension, Nasal congestion (finding)', '5/3/1996, nan, 999-17-4976, S99924959, X58550607X, Ms., Shane235, Wunsch504, nan, nan, nan, white, nonhispanic, F, Nizhny Novgorod  Nizhny Novgorod Oblast  RU, 155 Spinka Key, Boston, Massachusetts, Suffolk County, 2109.0, 42.24382202, -71.19304971, 501015.88, 2846.4, 3/10/2020, 4/1/2020, 6ec793c5-14fd-408f-8982-05e1266fa67b, 49727002.0, Cough (finding), Sore throat symptom (finding), Fever (finding), Loss of taste (finding)', '1/10/1916, 8/31/1984, 999-90-2276, S99956796, X30521847X, Mr., Cristobal567, Osorio731, nan, nan, M, white, hispanic, M, Panama City  Panama  PA, 762 Schmidt Gateway, Stow, Massachusetts, Middlesex County, nan, 42.44215829, -71.49530302, 1680489.4, 25890.01, 3/14/1938, nan, d9fc9523-5754-4ffa-97ef-9fabaf65fd55, 44054006.0, Diabetes, Chronic kidney disease stage 1 (disorder), Diabetic renal disease (disorder), Hypertension, Hypertriglyceridemia (disorder), Metabolic syndrome X (disorder), Osteoarthritis of knee, Neoplasm of prostate, Metastasis from malignant tumor of prostate (disorder)', '3/9/1930, nan, 999-20-7431, S99921262, X68783451X, Mr., Mary779, Legros616, nan, nan, M, white, nonhispanic, M, Boston  Massachusetts  US, 710 Bailey Parade, Amesbury, Massachusetts, Essex County, nan, 42.8768494, -70.96107574, 1552037.01, 539700.96, 12/28/1948, nan, 83a219ef-6ee3-42a0-99bc-d22c0643e7ec, 40055000.0, Chronic sinusitis (disorder), Opioid abuse (disorder), Smokes tobacco daily, Prediabetes, Anemia (disorder), Hyperlipidemia, Diabetes, Neuropathy due to type 2 diabetes mellitus (disorder), Hypertriglyceridemia (disorder), Metabolic syndrome X (disorder), Chronic kidney disease stage 1 (disorder), Diabetic renal disease (disorder), Neoplasm of prostate, Carcinoma in situ of prostate (disorder), Chronic intractable migraine without aura, Sore throat symptom (finding), Sputum finding (finding), Fatigue (finding), Hemoptysis (finding), Dyspnea (finding), Wheezing (finding), Fever (finding), Loss of taste (finding)', '9/7/1992, nan, 999-56-7732, S99978179, X79244170X, Mrs., Libby988, Oberbrunner298, nan, Strosin214, M, white, nonhispanic, F, Quincy  Massachusetts  US, 880 Effertz Fort, New Bedford, Massachusetts, Bristol County, 2748.0, 41.62843647, -70.92306453, 482959.37, 3095.45, 12/10/2006, nan, 8fb4077f-4fa2-4c6d-bcb4-965e980852ba, 124000000000000.0, Chronic intractable migraine without aura, Impacted molars, Chronic pain, Drug overdose, Normal pregnancy, Cough (finding), Sputum finding (finding), Dyspnea (finding), Wheezing (finding), Fever (finding)', '1/25/2015, nan, 999-52-6460, nan, nan, nan, Lionel365, Dickinson688, nan, nan, nan, white, nonhispanic, M, Leominster  Massachusetts  US, 1074 Kulas Promenade Unit 28, Shirley, Massachusetts, Middlesex County, 1464.0, 42.60861738, -71.62818225, 134740.72, 2015.72, 8/3/2019, 8/11/2019, a789710b-e8c5-4655-b66d-820c644f5120, 43878008.0, Streptococcal sore throat (disorder), Cough (finding), Sputum finding (finding), Chill (finding), Fever (finding)', '3/11/2004, nan, 999-70-4190, S99919185, nan, nan, Pablo44, Klein929, nan, nan, nan, white, nonhispanic, M, Franklin  Massachusetts  US, 188 Hane Center, Chicopee, Massachusetts, Hampden County, nan, 42.2051048, -72.56331605, 352326.01, 3116.44, 3/7/2020, 3/26/2020, ab61e2ff-8315-4a69-b92f-84add51ae886, 49727002.0, Cough (finding), Fatigue (finding), Fever (finding)']\n",
      "Y_train\n",
      " [1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\MCC\\anaconda3\\envs\\biotf\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Epoch 1/10, Average Training Loss: 0.3671693565595038\n",
      "Model saved for epoch 1 at Pre_train_epoch1.pt\n",
      "Validation Accuracy for epoch 1: 0.884929906542056\n",
      "Epoch 2/10, Average Training Loss: 0.320084329764468\n",
      "Model saved for epoch 2 at Pre_train_epoch2.pt\n",
      "Validation Accuracy for epoch 2: 0.883427903871829\n",
      "Epoch 3/10, Average Training Loss: 0.31441075814791686\n",
      "Model saved for epoch 3 at Pre_train_epoch3.pt\n",
      "Validation Accuracy for epoch 3: 0.8841789052069426\n",
      "Epoch 4/10, Average Training Loss: 0.3108887806219954\n",
      "Model saved for epoch 4 at Pre_train_epoch4.pt\n",
      "Validation Accuracy for epoch 4: 0.8841789052069426\n",
      "Epoch 5/10, Average Training Loss: 0.3103741247539229\n",
      "Model saved for epoch 5 at Pre_train_epoch5.pt\n",
      "Validation Accuracy for epoch 5: 0.884929906542056\n",
      "Epoch 6/10, Average Training Loss: 0.30494501469700547\n",
      "Model saved for epoch 6 at Pre_train_epoch6.pt\n",
      "Validation Accuracy for epoch 6: 0.883427903871829\n",
      "Epoch 7/10, Average Training Loss: 0.2898066947018037\n",
      "Model saved for epoch 7 at Pre_train_epoch7.pt\n",
      "Validation Accuracy for epoch 7: 0.884929906542056\n",
      "Epoch 8/10, Average Training Loss: 0.2673591434946852\n",
      "Model saved for epoch 8 at Pre_train_epoch8.pt\n",
      "Validation Accuracy for epoch 8: 0.8875166889185581\n",
      "Epoch 9/10, Average Training Loss: 0.23463945173409204\n",
      "Model saved for epoch 9 at Pre_train_epoch9.pt\n",
      "Validation Accuracy for epoch 9: 0.8884345794392523\n",
      "Epoch 10/10, Average Training Loss: 0.18761887309303235\n",
      "Model saved for epoch 10 at Pre_train_epoch10.pt\n",
      "Validation Accuracy for epoch 10: 0.8789218958611482\n"
     ]
    }
   ],
   "source": [
    "# Pre-train용\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CustomBertForSequenceClassification(BertForSequenceClassification):\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        labels=None,\n",
    "        output_hidden_states=True\n",
    "    ):\n",
    "        outputs = super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            labels=labels,\n",
    "            output_hidden_states=output_hidden_states\n",
    "        )\n",
    "        logits = outputs.logits\n",
    "        hidden_states = outputs.hidden_states[-8]  # n번째 레이어의 hidden states를 반환합니다.\n",
    "        loss = outputs.loss\n",
    "        return logits, loss, hidden_states\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "data_A = pd.read_csv(\"output1.csv\")  # data set A 파일명에 맞게 수정\n",
    "data_B = pd.read_csv(\"infected.csv\")  # data set B 파일명에 맞게 수정\n",
    "# 모델 저장 경로\n",
    "model_path = \"Pre-trained.pt\"\n",
    "\n",
    "# X_train, Y_train 생성\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for index, row in data_A.iterrows():  # 중복 제거를 하지 않고 원본 데이터 사용\n",
    "    patient_id = row[\"ID\"]\n",
    "    patient_info = [str(row[column]) for column in data_A.columns if column != \"ID\" and column != \"DESCRIPTION\"]\n",
    "    symptoms = \", \".join(data_A[data_A[\"ID\"] == patient_id][\"DESCRIPTION\"].tolist())\n",
    "    combined_info = \", \".join(patient_info) + \", \" + symptoms\n",
    "    X_train.append(combined_info)\n",
    "    if patient_id in data_B.values:\n",
    "        Y_train.append(1)\n",
    "    else:\n",
    "        Y_train.append(0)\n",
    "\n",
    "print(\"X_train\\n\", X_train[:10])\n",
    "print(\"Y_train\\n\", Y_train[:10])\n",
    "        \n",
    "# BERT 토크나이저 및 모델 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = CustomBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# 입력 데이터를 BERT의 입력 형식으로 변환\n",
    "max_len = 128  # 입력 시퀀스의 최대 길이\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for info in X_train:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        info,                         # 환자 정보 및 증상\n",
    "                        add_special_tokens = True,    # [CLS], [SEP] 토큰 추가\n",
    "                        max_length = max_len,         # 최대 길이 지정\n",
    "                        pad_to_max_length = True,     # 패딩을 추가하여 최대 길이로 맞춤\n",
    "                        return_attention_mask = True, # 어텐션 마스크 생성\n",
    "                        return_tensors = 'pt',        # PyTorch 텐서로 반환\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(Y_train)\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "train_size = 0.8\n",
    "train_dataset, val_dataset = train_test_split(dataset, test_size=1-train_size, random_state=42)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# 모델을 GPU로 이동\n",
    "model.to(device)\n",
    "\n",
    "# 옵티마이저 및 학습률 설정\n",
    "# 기본 학습률 : 2e-6\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# 에폭 설정\n",
    "epochs = 10\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels': batch[2]}\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[1]  # loss가 outputs의 두 번째 값입니다.\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}')\n",
    "\n",
    "    # 모델 저장 및 평가\n",
    "    model_save_path = f\"Pre_train_epoch{epoch + 1}.pt\"\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Model saved for epoch {epoch + 1} at {model_save_path}\")\n",
    "    \n",
    "    model.eval()\n",
    "    val_accuracy = 0\n",
    "    for batch in val_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels': batch[2]}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        logits = outputs[0]  # logits가 outputs의 첫 번째 값입니다.\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        val_accuracy += (logits.argmax(axis=1) == label_ids).mean().item()\n",
    "\n",
    "    print(f'Validation Accuracy for epoch {epoch + 1}: {val_accuracy / len(val_dataloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d715e452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\n",
      " ['11/6/2011, nan, 999-81-9641, nan, nan, nan, Mack300, Halvorson124, nan, nan, nan, asian, nonhispanic, M, Avon  Massachusetts  US, 617 Hane Corner Unit 24, New Bedford, Massachusetts, Bristol County, 2743.0, 41.5103414, -70.9350167, 26475.3, 2679.84, 12/29/2019, 1/12/2020, 566f4d11-728e-49c2-8954-d17fedd7037b, 444814009.0, Viral sinusitis (disorder), Nasal congestion (finding), Cough (finding), Fever (finding), Loss of taste (finding)', '3/3/2000, nan, 999-39-4367, S99951818, X24980388X, Ms., Renee555, Blanda868, nan, nan, nan, white, nonhispanic, F, Natick  Massachusetts  US, 176 Dicki Highlands, Salisbury, Massachusetts, Essex County, nan, 42.80175139, -70.84150456, 538129.79, 2975.64, 4/27/2018, nan, c6f413a4-eb4a-4d1f-ad1a-61585fad9b2e, 59621000.0, Hypertension, Sputum finding (finding), Fever (finding), Normal pregnancy', '7/27/1951, 8/16/2018, 999-92-8207, S99933636, X43360252X, Mrs., Kristin64, Mann644, JD, Price929, M, white, nonhispanic, F, Worcester  Massachusetts  US, 509 Mueller Terrace, Weymouth, Massachusetts, Norfolk County, 2189.0, 42.20259477, -70.98242938, 1598069.11, 11444.13, 2/15/1963, nan, d092b678-5492-4158-a4e1-069b1367d78f, 40055000.0, Chronic sinusitis (disorder), Body mass index 30+ - obesity (finding), Hyperlipidemia, Stroke, Chronic congestive heart failure (disorder)', '7/11/1988, nan, 999-79-7595, S99950320, X36863170X, Mrs., Margret280, Orn563, nan, Swift555, M, asian, nonhispanic, F, Quincy  Massachusetts  US, 757 Kling Walk, Newton, Massachusetts, Middlesex County, nan, 42.3015182, -71.23202754, 654892.71, 9627.95, 9/4/2006, nan, 6ad72601-1d8c-439f-86df-6fedd8e5158c, 59621000.0, Hypertension, Cough (finding), Nausea (finding), Vomiting symptom (finding), Fever (finding), Loss of taste (finding)', '11/12/2013, nan, 999-96-9038, nan, nan, nan, Jewell855, Rogahn59, nan, nan, nan, white, nonhispanic, F, Whitman  Massachusetts  US, 749 McCullough Haven, Scituate, Massachusetts, Plymouth County, 2066.0, 42.23128626, -70.74126649, 142360.93, 2045.72, 2/29/2020, 3/25/2020, 2b8ac8a6-b2c6-4a60-a666-a04365f6815a, 49727002.0, Cough (finding), Dyspnea (finding), Wheezing (finding), Diarrhea symptom (finding), Fever (finding)', '1/23/1973, nan, 999-71-6176, S99936713, X67522812X, Ms., Olinda137, Price929, nan, nan, S, asian, hispanic, F, Marlborough  Massachusetts  US, 456 Beer Meadow Suite 57, Lawrence, Massachusetts, Essex County, nan, 42.72599632, -71.20616789, 125031.19, 8992.56, 3/28/1995, nan, 1d2dffc3-d2f9-4e02-8092-62d75bd6ab8b, 15777000.0, Prediabetes, Anemia (disorder), Viral sinusitis (disorder), Cough (finding), Fatigue (finding), Fever (finding)', '6/18/1916, 2/10/2002, 999-50-8868, S99952467, X74309188X, Mr., Lauren941, Bartell116, nan, nan, S, black, nonhispanic, M, Hingham  Massachusetts  US, 673 Ferry Meadow Apt 40, Dedham, Massachusetts, Norfolk County, nan, 42.29579173, -71.21534964, 1887028.81, 396114.89, 6/22/1958, nan, 28781692-ea28-40ab-a2d2-cdc2e88c9fdf, 44054006.0, Diabetes, Chronic kidney disease stage 1 (disorder), Diabetic renal disease (disorder), Hypertriglyceridemia (disorder), Metabolic syndrome X (disorder), Atrial Fibrillation, Osteoporosis (disorder), Stroke, Chronic sinusitis (disorder), Neoplasm of prostate, Carcinoma in situ of prostate (disorder)', '1/11/1967, nan, 999-84-5643, S99929369, X11626259X, Ms., Eloisa55, Benavides239, nan, nan, S, black, hispanic, F, Puebla  Puebla  MX, 851 Hegmann Mission, Carver, Massachusetts, Plymouth County, nan, 41.90402557, -70.71519819, 1136108.37, 12688.98, 4/13/1977, nan, ef79c31d-1661-422f-b4b3-44f0ef8c237d, 410429000.0, Cardiac Arrest, History of cardiac arrest (situation), Hypertension, Miscarriage in first trimester, Tubal pregnancy, Tubal pregnancy, Prediabetes, Anemia (disorder), Cough (finding), Fever (finding)', '6/21/1916, 6/27/2014, 999-25-8699, S99932304, X83260871X, Mr., Marion502, Schinner682, nan, nan, S, white, nonhispanic, M, Methuen  Massachusetts  US, 957 Kreiger Mall, Dennis, Massachusetts, Barnstable County, 2638.0, 41.74773953, -70.17706599, 1843702.42, 31052.46, 8/27/1944, nan, cc720fc1-bb56-472a-bc68-27b3d16b1e00, 40055000.0, Chronic sinusitis (disorder), Body mass index 30+ - obesity (finding), Hyperlipidemia, Neoplasm of prostate, Carcinoma in situ of prostate (disorder), Osteoporosis (disorder), Atrial Fibrillation, Stroke, Coronary Heart Disease, Chronic congestive heart failure (disorder), Acute bronchitis (disorder)', '9/26/1953, nan, 999-10-4564, S99934299, X28221847X, Mr., Emory494, Nolan344, nan, nan, M, asian, nonhispanic, M, Winthrop  Massachusetts  US, 293 Mertz Harbor, New Bedford, Massachusetts, Bristol County, 2746.0, 41.7017427, -70.94444646, 1425359.14, 20978.79, 11/20/1971, nan, 35ef04f0-2aaf-4799-b018-b2b72aa300af, 59621000.0, Hypertension, Prediabetes, Anemia (disorder), Chronic sinusitis (disorder), Otitis media, Cough (finding), Sputum finding (finding), Fatigue (finding), Fever (finding), Loss of taste (finding), Pneumonia (disorder), Hypoxemia (disorder), Respiratory distress (finding), Acute respiratory failure (disorder), Sepsis caused by virus (disorder), Acute deep venous thrombosis (disorder), Acquired coagulation disorder (disorder)']\n",
      "Y_train\n",
      " [1, 1, 0, 1, 1, 1, 0, 1, 0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-train model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MCC\\anaconda3\\envs\\biotf\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Epoch 1/10, Average Training Loss: 0.36177403558560506\n",
      "Model saved for epoch 1 at Fine_tuned_epoch1.pt\n",
      "Validation Accuracy for epoch 1: 0.8891129032258065\n",
      "Epoch 2/10, Average Training Loss: 0.31443726943760386\n",
      "Model saved for epoch 2 at Fine_tuned_epoch2.pt\n",
      "Validation Accuracy for epoch 2: 0.8879928315412187\n",
      "Epoch 3/10, Average Training Loss: 0.30399539108138257\n",
      "Model saved for epoch 3 at Fine_tuned_epoch3.pt\n",
      "Validation Accuracy for epoch 3: 0.8895609318996416\n",
      "Epoch 4/10, Average Training Loss: 0.2997790468417532\n",
      "Model saved for epoch 4 at Fine_tuned_epoch4.pt\n",
      "Validation Accuracy for epoch 4: 0.8911290322580645\n",
      "Epoch 5/10, Average Training Loss: 0.2947152891779334\n",
      "Model saved for epoch 5 at Fine_tuned_epoch5.pt\n",
      "Validation Accuracy for epoch 5: 0.8859767025089605\n",
      "Epoch 6/10, Average Training Loss: 0.2923556942818308\n",
      "Model saved for epoch 6 at Fine_tuned_epoch6.pt\n",
      "Validation Accuracy for epoch 6: 0.8911290322580645\n",
      "Epoch 7/10, Average Training Loss: 0.2918317484843537\n",
      "Model saved for epoch 7 at Fine_tuned_epoch7.pt\n",
      "Validation Accuracy for epoch 7: 0.8864247311827957\n",
      "Epoch 8/10, Average Training Loss: 0.28140943570107946\n",
      "Model saved for epoch 8 at Fine_tuned_epoch8.pt\n",
      "Validation Accuracy for epoch 8: 0.8931451612903226\n",
      "Epoch 9/10, Average Training Loss: 0.2723436249889494\n",
      "Model saved for epoch 9 at Fine_tuned_epoch9.pt\n",
      "Validation Accuracy for epoch 9: 0.8884408602150538\n",
      "Epoch 10/10, Average Training Loss: 0.2640499152182563\n",
      "Model saved for epoch 10 at Fine_tuned_epoch10.pt\n",
      "Validation Accuracy for epoch 10: 0.8900089605734768\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune용\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CustomBertForSequenceClassification(BertForSequenceClassification):\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        labels=None,\n",
    "        output_hidden_states=True\n",
    "    ):\n",
    "        outputs = super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            labels=labels,\n",
    "            output_hidden_states=output_hidden_states\n",
    "        )\n",
    "        logits = outputs.logits\n",
    "        hidden_states = outputs.hidden_states[-8]  # n번째 레이어의 hidden states를 반환합니다.\n",
    "        loss = outputs.loss\n",
    "        return logits, loss, hidden_states\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "data_A = pd.read_csv(\"output3.csv\")  # data set A 파일명에 맞게 수정\n",
    "data_B = pd.read_csv(\"infected.csv\")  # data set B 파일명에 맞게 수정\n",
    "# 모델 불러오는 경로\n",
    "model_path = \"Pre_train_epoch10.pt\"\n",
    "# 모델 저장경로\n",
    "model_path2 = \"Fine-tuned.pt\"\n",
    "\n",
    "# X_train, Y_train 생성\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for index, row in data_A.iterrows():  # 중복 제거를 하지 않고 원본 데이터 사용\n",
    "    patient_id = row[\"ID\"]\n",
    "    patient_info = [str(row[column]) for column in data_A.columns if column != \"ID\" and column != \"DESCRIPTION\"]\n",
    "    symptoms = \", \".join(data_A[data_A[\"ID\"] == patient_id][\"DESCRIPTION\"].tolist())\n",
    "    combined_info = \", \".join(patient_info) + \", \" + symptoms\n",
    "    X_train.append(combined_info)\n",
    "    if patient_id in data_B.values:\n",
    "        Y_train.append(1)\n",
    "    else:\n",
    "        Y_train.append(0)\n",
    "\n",
    "print(\"X_train\\n\", X_train[:10])\n",
    "print(\"Y_train\\n\", Y_train[:10])\n",
    "        \n",
    "# BERT 토크나이저 및 모델 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# 모델이 이미 저장되어 있는지 확인하고, 저장된 모델이 있으면 불러오고 없으면 새로운 모델 생성\n",
    "if os.path.exists(model_path):\n",
    "    # 저장된 모델이 있을 경우 불러오기\n",
    "    model = CustomBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(\"Pre-train model loaded.\")\n",
    "else:\n",
    "    # 저장된 모델이 없을 경우 새로운 모델 생성\n",
    "    model = CustomBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "    print(\"New model generated.\")\n",
    "\n",
    "# 입력 데이터를 BERT의 입력 형식으로 변환\n",
    "max_len = 128  # 입력 시퀀스의 최대 길이\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for info in X_train:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        info,                         # 환자 정보 및 증상\n",
    "                        add_special_tokens = True,    # [CLS], [SEP] 토큰 추가\n",
    "                        max_length = max_len,         # 최대 길이 지정\n",
    "                        pad_to_max_length = True,     # 패딩을 추가하여 최대 길이로 맞춤\n",
    "                        return_attention_mask = True, # 어텐션 마스크 생성\n",
    "                        return_tensors = 'pt',        # PyTorch 텐서로 반환\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(Y_train)\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "train_size = 0.8\n",
    "train_dataset, val_dataset = train_test_split(dataset, test_size=1-train_size, random_state=42)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# 모델을 GPU로 이동\n",
    "model.to(device)\n",
    "\n",
    "# 옵티마이저 및 학습률 설정\n",
    "# 기본 학습률 : 2e-6\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-6)\n",
    "\n",
    "# 에폭 설정\n",
    "epochs = 10\n",
    "\n",
    "# 학습 루프\n",
    "hidden_states_list = []  # 모든 에폭에 대한 hidden state를 저장할 리스트\n",
    "# 학습 루프\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels': batch[2]}\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[1]  # loss가 outputs의 두 번째 값입니다.\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}')\n",
    "\n",
    "    # 모델 저장 및 평가\n",
    "    model_save_path = f\"Fine_tuned_epoch{epoch + 1}.pt\"\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Model saved for epoch {epoch + 1} at {model_save_path}\")\n",
    "    \n",
    "    model.eval()\n",
    "    val_accuracy = 0\n",
    "    for batch in val_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels': batch[2]}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        logits = outputs[0]  # logits가 outputs의 첫 번째 값입니다.\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        val_accuracy += (logits.argmax(axis=1) == label_ids).mean().item()\n",
    "\n",
    "    print(f'Validation Accuracy for epoch {epoch + 1}: {val_accuracy / len(val_dataloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93cb1611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 랜덤분할(500/500/250)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def sample_csv_and_additional(input_file, output_file_500, output_file_100, n_500):\n",
    "    # CSV 파일을 읽어옵니다.\n",
    "    data = pd.read_csv(input_file)\n",
    "    \n",
    "    # 데이터를 랜덤하게 샘플링합니다.\n",
    "    sampled_data_750 = data.sample(n=n_500, random_state=42)\n",
    "    \n",
    "    # 첫 250개 데이터를 output_file_500과 output_file_100에 순서대로 삽입합니다.\n",
    "    first_250 = sampled_data_750[:250]\n",
    "    first_250.to_csv(output_file_500, index=False)\n",
    "    first_250.to_csv(output_file_100, index=False)\n",
    "    \n",
    "    # 나머지 500개 데이터를 절반으로 나누어 각각 output_file_500과 output_file_100에 추가합니다.\n",
    "    remaining_500 = sampled_data_750[250:]\n",
    "    split_idx = len(remaining_500) // 2\n",
    "    second_250_500 = remaining_500[:split_idx]\n",
    "    second_250_100 = remaining_500[split_idx:]\n",
    "    \n",
    "    # 파일에 추가합니다.\n",
    "    second_250_500.to_csv(output_file_500, mode='a', header=False, index=False)\n",
    "    second_250_100.to_csv(output_file_100, mode='a', header=False, index=False)\n",
    "\n",
    "# 입력 CSV 파일 경로\n",
    "input_file = \"output6.csv\"\n",
    "\n",
    "# 출력 CSV 파일 경로\n",
    "output_file_500 = \"random_500_D.csv\"\n",
    "output_file_100 = \"random_500_C.csv\"\n",
    "\n",
    "# 랜덤하게 추출할 데이터 개수\n",
    "n_500 = 750\n",
    "\n",
    "# 함수 호출\n",
    "sample_csv_and_additional(input_file, output_file_500, output_file_100, n_500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97fe8245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 랜덤분할(300/500)\n",
    "import pandas as pd\n",
    "\n",
    "def sample_csv_and_additional(input_file, output_file_500, output_file_100, n_500):\n",
    "    # CSV 파일을 읽어옵니다.\n",
    "    data = pd.read_csv(input_file)\n",
    "    \n",
    "    # 데이터를 랜덤하게 샘플링합니다.\n",
    "    sampled_data_500 = data.sample(n=n_500, random_state=42)\n",
    "    \n",
    "    # 샘플링된 500개의 데이터를 CSV 파일로 내보냅니다.\n",
    "    sampled_data_500.to_csv(output_file_500, index=False)\n",
    "    \n",
    "    # sampled_data_500에서 첫 100개의 데이터를 선택합니다.\n",
    "    sampled_data_100 = sampled_data_500.head(300)\n",
    "    \n",
    "    # 선택된 첫 100개의 데이터를 CSV 파일로 내보냅니다.\n",
    "    sampled_data_100.to_csv(output_file_100, index=False)\n",
    "\n",
    "# 입력 CSV 파일 경로\n",
    "input_file = \"output6.csv\"\n",
    "\n",
    "# 출력 CSV 파일 경로\n",
    "output_file_500 = \"random_500.csv\"\n",
    "output_file_100 = \"random_300.csv\"\n",
    "\n",
    "# 랜덤하게 추출할 데이터 개수\n",
    "n_500 = 500\n",
    "\n",
    "# 함수 호출\n",
    "sample_csv_and_additional(input_file, output_file_500, output_file_100, n_500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3936463d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\n",
      " ['6/6/1971, nan, 999-71-5643, S99989143, X60757569X, Mr., Tracy345, Skiles927, nan, nan, M, white, nonhispanic, M, Marblehead  Massachusetts  US, 884 Auer Annex, Uxbridge, Massachusetts, Worcester County, nan, 42.10399442, -71.60337809, 1307003.54, 4997.12, 6/5/1974, nan, 5921ab74-99b6-49c9-a7d3-ad8349070ca8, 128613002.0, Seizure disorder, History of single seizure (situation), Hypertension, Body mass index 30+ - obesity (finding), Cough (finding), Sore throat symptom (finding), Viral sinusitis (disorder)', '10/28/1915, 3/3/1990, 999-77-6721, S99996606, X31277871X, Mrs., Londa304, Hessel84, nan, Weimann465, M, white, nonhispanic, F, Somerville  Massachusetts  US, 136 Ratke Manor, Dighton, Massachusetts, Bristol County, nan, 41.81765972, -71.18273423, 1416726.1, 356060.14, 12/21/1933, nan, e9e9254b-75fb-4c28-8694-4ac7c5d8f076, 59621000.0, Hypertension, Cardiac Arrest, History of cardiac arrest (situation), Prediabetes, Anemia (disorder), Smokes tobacco daily, Atrial Fibrillation, Osteoporosis (disorder), Suspected lung cancer (situation), Non-small cell lung cancer (disorder), Non-small cell carcinoma of lung  TNM stage 1 (disorder)', '3/26/1959, nan, 999-73-9949, S99912497, X76883574X, Mr., Leigh689, Lubowitz58, nan, nan, M, white, nonhispanic, M, Boston  Massachusetts  US, 798 Gislason Green Suite 35, Wakefield, Massachusetts, Middlesex County, 1880.0, 42.53756166, -71.10288984, 1259117.57, 8186.52, 5/3/1973, nan, e84d2538-70ed-4b84-9f60-b3bba2db29aa, 40055000.0, Chronic sinusitis (disorder), Prediabetes, Anemia (disorder), Sputum finding (finding), Muscle pain (finding), Joint pain (finding), Chill (finding), Fever (finding)', '8/22/2000, nan, 999-88-6112, S99980594, nan, Mr., Christian753, Williamson769, nan, nan, nan, white, nonhispanic, M, Chelsea  Massachusetts  US, 348 Beier Walk Unit 18, Medford, Massachusetts, Middlesex County, nan, 42.40204749, -71.15136114, 470224.81, 7369.28, 8/29/2002, 11/28/2019, 2f607765-6ce9-4a23-a7dd-d300d7519ed8, 233678006.0, Childhood asthma, Sore throat symptom (finding), Muscle pain (finding), Joint pain (finding), Fever (finding)', '4/3/1969, nan, 999-83-4435, S99964476, X10469354X, Mr., Miquel905, Bergstrom287, nan, nan, M, white, nonhispanic, M, Rutland  Massachusetts  US, 907 Waelchi Meadow, Yarmouth, Massachusetts, Barnstable County, nan, 41.69846053, -70.19125785, 159128.47, 12807.34, 5/28/1987, nan, b07c150b-1121-4dd5-bc3b-8dafc8aa0cd4, 59621000.0, Hypertension, Body mass index 30+ - obesity (finding), Prediabetes, Anemia (disorder), Passive conjunctival congestion (finding), Nasal congestion (finding), Headache (finding), Sputum finding (finding), Dyspnea (finding), Wheezing (finding), Muscle pain (finding), Joint pain (finding), Chill (finding), Fever (finding), Pneumonia (disorder), Hypoxemia (disorder), Respiratory distress (finding), Acute respiratory failure (disorder)', '12/23/1978, nan, 999-46-3971, S99934683, X47947758X, Mrs., Ginny287, Jacobi462, nan, Lowe577, M, white, nonhispanic, F, Chicopee  Massachusetts  US, 396 Rolfson Rue Suite 45, Topsfield, Massachusetts, Essex County, 1983.0, 42.61484752, -70.96895139, 874657.71, 9905.36, 10/12/1996, nan, 0deed51b-6ac6-4082-bad4-741b6535dae6, 19169002.0, Miscarriage in first trimester, Tubal pregnancy, Fever (finding), Pneumonia (disorder), Hypoxemia (disorder), Respiratory distress (finding), Acute respiratory failure (disorder), Acute pulmonary embolism (disorder)', '9/18/1913, 12/25/1941, 999-47-5808, S99965672, X23440298X, Mr., Sean831, Ortiz186, nan, nan, M, white, nonhispanic, M, Lowell  Massachusetts  US, 660 Witting Wynd Apt 43, New Bedford, Massachusetts, Bristol County, nan, 41.50313818, -70.96233177, 721878.08, 3388.84, 9/21/1922, nan, c7f72687-1a24-47b0-a0b6-bd7d6f7f3ae6, 53741008.0, Coronary Heart Disease, Body mass index 30+ - obesity (finding), Myocardial Infarction, History of myocardial infarction (situation)', '3/30/1973, nan, 999-24-4798, S99973068, X58162558X, Mr., Antonio44, de Jesús414, nan, nan, M, white, hispanic, M, San Jose  San Jose  CR, 581 Hegmann Parade Unit 6, Boston, Massachusetts, Suffolk County, 2116.0, 42.33565998, -71.09985379, 28526.83, 0.0, 5/24/1991, nan, 8ed11571-c3db-42f0-929c-2a5cfa9d64ef, 59621000.0, Hypertension, Chronic sinusitis (disorder), Body mass index 30+ - obesity (finding), Cardiac Arrest, History of cardiac arrest (situation)', '3/30/1961, nan, 999-77-1694, S99983819, X60733746X, Mr., Scot349, Roob72, nan, nan, M, white, nonhispanic, M, Wilbraham  Massachusetts  US, 984 Carter Ville, Freetown, Massachusetts, Bristol County, nan, 41.79856891, -71.02463315, 1568579.28, 4293.84, 6/5/1986, nan, 0db7df06-9396-495f-95be-a41a7aeb47e4, 15777000.0, Prediabetes, Anemia (disorder), Polyp of colon, Recurrent rectal polyp, Cough (finding), Sputum finding (finding), Fatigue (finding), Fever (finding), Loss of taste (finding)', '3/29/1963, nan, 999-88-1846, S99998162, X82291653X, Mr., Curtis94, Wisoky380, nan, nan, M, white, hispanic, M, Gardner  Massachusetts  US, 791 Hyatt Brook Suite 91, Whitman, Massachusetts, Plymouth County, nan, 42.09500085, -70.97998572, 1462391.83, 11628.96, 5/22/1981, nan, 138b9a30-8b75-4f9c-bb81-e7fb0f2e51e4, 59621000.0, Hypertension, Body mass index 30+ - obesity (finding), Chronic sinusitis (disorder), Cough (finding), Sputum finding (finding), Dyspnea (finding), Wheezing (finding), Fever (finding), Loss of taste (finding), Pneumonia (disorder), Hypoxemia (disorder), Respiratory distress (finding), Sepsis caused by virus (disorder)']\n",
      "Y_train\n",
      " [1, 0, 1, 1, 1, 1, 0, 0, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-train model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MCC\\anaconda3\\envs\\biotf\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Validation Accuracy: 0.884765625\n"
     ]
    }
   ],
   "source": [
    "# smashed data 생성 (500/server side)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CustomBertForSequenceClassification(BertForSequenceClassification):\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        labels=None,\n",
    "        output_hidden_states=True\n",
    "    ):\n",
    "        outputs = super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            labels=labels,\n",
    "            output_hidden_states=output_hidden_states\n",
    "        )\n",
    "        logits = outputs.logits\n",
    "        hidden_states = outputs.hidden_states[-6]  # n번째 레이어의 hidden states를 반환합니다.\n",
    "        loss = outputs.loss\n",
    "        return logits, loss, hidden_states\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "data_A = pd.read_csv(\"random_500.csv\")  # data set A 파일명에 맞게 수정\n",
    "data_B = pd.read_csv(\"infected.csv\")  # data set B 파일명에 맞게 수정\n",
    "# 모델 저장 경로\n",
    "model_path = \"Pre_train_epoch10.pt\"\n",
    "\n",
    "# X_train, Y_train 생성\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for index, row in data_A.iterrows():  # 중복 제거를 하지 않고 원본 데이터 사용\n",
    "    patient_id = row[\"ID\"]\n",
    "    patient_info = [str(row[column]) for column in data_A.columns if column != \"ID\" and column != \"DESCRIPTION\"]\n",
    "    symptoms = \", \".join(data_A[data_A[\"ID\"] == patient_id][\"DESCRIPTION\"].tolist())\n",
    "    combined_info = \", \".join(patient_info) + \", \" + symptoms\n",
    "    X_train.append(combined_info)\n",
    "    if patient_id in data_B.values:\n",
    "        Y_train.append(1)\n",
    "    else:\n",
    "        Y_train.append(0)\n",
    "\n",
    "print(\"X_train\\n\", X_train[:10])\n",
    "print(\"Y_train\\n\", Y_train[:10])\n",
    "        \n",
    "# BERT 토크나이저 및 모델 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# 모델이 이미 저장되어 있는지 확인하고, 저장된 모델이 있으면 불러오고 없으면 새로운 모델 생성\n",
    "if os.path.exists(model_path):\n",
    "    # 저장된 모델이 있을 경우 불러오기\n",
    "    model = CustomBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(\"Pre-train model loaded.\")\n",
    "else:\n",
    "    # 저장된 모델이 없을 경우 새로운 모델 생성\n",
    "    model = CustomBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "    print(\"New model generated.\")\n",
    "\n",
    "# 입력 데이터를 BERT의 입력 형식으로 변환\n",
    "max_len = 128  # 입력 시퀀스의 최대 길이\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for info in X_train:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        info,                         # 환자 정보 및 증상\n",
    "                        add_special_tokens = True,    # [CLS], [SEP] 토큰 추가\n",
    "                        max_length = max_len,         # 최대 길이 지정\n",
    "                        pad_to_max_length = True,     # 패딩을 추가하여 최대 길이로 맞춤\n",
    "                        return_attention_mask = True, # 어텐션 마스크 생성\n",
    "                        return_tensors = 'pt',        # PyTorch 텐서로 반환\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(Y_train)\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# 데이터로더 생성\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# 모델을 GPU로 이동\n",
    "model.to(device)\n",
    "\n",
    "# 모델 평가\n",
    "model.eval()\n",
    "val_accuracy = 0\n",
    "hidden_states_list = []  # 평가할 때 hidden state를 저장할 리스트\n",
    "for batch in dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    inputs = {'input_ids': batch[0],\n",
    "              'attention_mask': batch[1],\n",
    "              'labels': batch[2]}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs[0]  # logits가 outputs의 첫 번째 값입니다.\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = inputs['labels'].cpu().numpy()\n",
    "    val_accuracy += (logits.argmax(axis=1) == label_ids).mean().item()\n",
    "    # hidden state를 저장합니다.\n",
    "    hidden_states = outputs[2]\n",
    "    hidden_states_list.append(hidden_states)\n",
    "hidden_states_concat = torch.cat(hidden_states_list, dim=0)\n",
    "hidden_states_concat = hidden_states_concat[:, 0, :].cpu().detach().numpy()\n",
    "hidden_states_df = pd.DataFrame(hidden_states_concat)\n",
    "hidden_states_df.to_csv(\"Dictionary_smashed_data.csv\", index=False)\n",
    "\n",
    "print(f'Validation Accuracy: {val_accuracy / len(dataloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ef0b701f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\n",
      " ['6/6/1971, nan, 999-71-5643, S99989143, X60757569X, Mr., Tracy345, Skiles927, nan, nan, M, white, nonhispanic, M, Marblehead  Massachusetts  US, 884 Auer Annex, Uxbridge, Massachusetts, Worcester County, nan, 42.10399442, -71.60337809, 1307003.54, 4997.12, 6/5/1974, nan, 5921ab74-99b6-49c9-a7d3-ad8349070ca8, 128613002.0, Seizure disorder, History of single seizure (situation), Hypertension, Body mass index 30+ - obesity (finding), Cough (finding), Sore throat symptom (finding), Viral sinusitis (disorder)', '10/28/1915, 3/3/1990, 999-77-6721, S99996606, X31277871X, Mrs., Londa304, Hessel84, nan, Weimann465, M, white, nonhispanic, F, Somerville  Massachusetts  US, 136 Ratke Manor, Dighton, Massachusetts, Bristol County, nan, 41.81765972, -71.18273423, 1416726.1, 356060.14, 12/21/1933, nan, e9e9254b-75fb-4c28-8694-4ac7c5d8f076, 59621000.0, Hypertension, Cardiac Arrest, History of cardiac arrest (situation), Prediabetes, Anemia (disorder), Smokes tobacco daily, Atrial Fibrillation, Osteoporosis (disorder), Suspected lung cancer (situation), Non-small cell lung cancer (disorder), Non-small cell carcinoma of lung  TNM stage 1 (disorder)', '3/26/1959, nan, 999-73-9949, S99912497, X76883574X, Mr., Leigh689, Lubowitz58, nan, nan, M, white, nonhispanic, M, Boston  Massachusetts  US, 798 Gislason Green Suite 35, Wakefield, Massachusetts, Middlesex County, 1880.0, 42.53756166, -71.10288984, 1259117.57, 8186.52, 5/3/1973, nan, e84d2538-70ed-4b84-9f60-b3bba2db29aa, 40055000.0, Chronic sinusitis (disorder), Prediabetes, Anemia (disorder), Sputum finding (finding), Muscle pain (finding), Joint pain (finding), Chill (finding), Fever (finding)', '8/22/2000, nan, 999-88-6112, S99980594, nan, Mr., Christian753, Williamson769, nan, nan, nan, white, nonhispanic, M, Chelsea  Massachusetts  US, 348 Beier Walk Unit 18, Medford, Massachusetts, Middlesex County, nan, 42.40204749, -71.15136114, 470224.81, 7369.28, 8/29/2002, 11/28/2019, 2f607765-6ce9-4a23-a7dd-d300d7519ed8, 233678006.0, Childhood asthma, Sore throat symptom (finding), Muscle pain (finding), Joint pain (finding), Fever (finding)', '4/3/1969, nan, 999-83-4435, S99964476, X10469354X, Mr., Miquel905, Bergstrom287, nan, nan, M, white, nonhispanic, M, Rutland  Massachusetts  US, 907 Waelchi Meadow, Yarmouth, Massachusetts, Barnstable County, nan, 41.69846053, -70.19125785, 159128.47, 12807.34, 5/28/1987, nan, b07c150b-1121-4dd5-bc3b-8dafc8aa0cd4, 59621000.0, Hypertension, Body mass index 30+ - obesity (finding), Prediabetes, Anemia (disorder), Passive conjunctival congestion (finding), Nasal congestion (finding), Headache (finding), Sputum finding (finding), Dyspnea (finding), Wheezing (finding), Muscle pain (finding), Joint pain (finding), Chill (finding), Fever (finding), Pneumonia (disorder), Hypoxemia (disorder), Respiratory distress (finding), Acute respiratory failure (disorder)', '12/23/1978, nan, 999-46-3971, S99934683, X47947758X, Mrs., Ginny287, Jacobi462, nan, Lowe577, M, white, nonhispanic, F, Chicopee  Massachusetts  US, 396 Rolfson Rue Suite 45, Topsfield, Massachusetts, Essex County, 1983.0, 42.61484752, -70.96895139, 874657.71, 9905.36, 10/12/1996, nan, 0deed51b-6ac6-4082-bad4-741b6535dae6, 19169002.0, Miscarriage in first trimester, Tubal pregnancy, Fever (finding), Pneumonia (disorder), Hypoxemia (disorder), Respiratory distress (finding), Acute respiratory failure (disorder), Acute pulmonary embolism (disorder)', '9/18/1913, 12/25/1941, 999-47-5808, S99965672, X23440298X, Mr., Sean831, Ortiz186, nan, nan, M, white, nonhispanic, M, Lowell  Massachusetts  US, 660 Witting Wynd Apt 43, New Bedford, Massachusetts, Bristol County, nan, 41.50313818, -70.96233177, 721878.08, 3388.84, 9/21/1922, nan, c7f72687-1a24-47b0-a0b6-bd7d6f7f3ae6, 53741008.0, Coronary Heart Disease, Body mass index 30+ - obesity (finding), Myocardial Infarction, History of myocardial infarction (situation)', '3/30/1973, nan, 999-24-4798, S99973068, X58162558X, Mr., Antonio44, de Jesús414, nan, nan, M, white, hispanic, M, San Jose  San Jose  CR, 581 Hegmann Parade Unit 6, Boston, Massachusetts, Suffolk County, 2116.0, 42.33565998, -71.09985379, 28526.83, 0.0, 5/24/1991, nan, 8ed11571-c3db-42f0-929c-2a5cfa9d64ef, 59621000.0, Hypertension, Chronic sinusitis (disorder), Body mass index 30+ - obesity (finding), Cardiac Arrest, History of cardiac arrest (situation)', '3/30/1961, nan, 999-77-1694, S99983819, X60733746X, Mr., Scot349, Roob72, nan, nan, M, white, nonhispanic, M, Wilbraham  Massachusetts  US, 984 Carter Ville, Freetown, Massachusetts, Bristol County, nan, 41.79856891, -71.02463315, 1568579.28, 4293.84, 6/5/1986, nan, 0db7df06-9396-495f-95be-a41a7aeb47e4, 15777000.0, Prediabetes, Anemia (disorder), Polyp of colon, Recurrent rectal polyp, Cough (finding), Sputum finding (finding), Fatigue (finding), Fever (finding), Loss of taste (finding)', '3/29/1963, nan, 999-88-1846, S99998162, X82291653X, Mr., Curtis94, Wisoky380, nan, nan, M, white, hispanic, M, Gardner  Massachusetts  US, 791 Hyatt Brook Suite 91, Whitman, Massachusetts, Plymouth County, nan, 42.09500085, -70.97998572, 1462391.83, 11628.96, 5/22/1981, nan, 138b9a30-8b75-4f9c-bb81-e7fb0f2e51e4, 59621000.0, Hypertension, Body mass index 30+ - obesity (finding), Chronic sinusitis (disorder), Cough (finding), Sputum finding (finding), Dyspnea (finding), Wheezing (finding), Fever (finding), Loss of taste (finding), Pneumonia (disorder), Hypoxemia (disorder), Respiratory distress (finding), Sepsis caused by virus (disorder)']\n",
      "Y_train\n",
      " [1, 0, 1, 1, 1, 1, 0, 0, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-train model loaded.\n",
      "True\n",
      "Validation Accuracy: 0.9067982456140351\n"
     ]
    }
   ],
   "source": [
    "# smashed data 생성 (100/client side)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CustomBertForSequenceClassification(BertForSequenceClassification):\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        labels=None,\n",
    "        output_hidden_states=True\n",
    "    ):\n",
    "        outputs = super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            labels=labels,\n",
    "            output_hidden_states=output_hidden_states\n",
    "        )\n",
    "        logits = outputs.logits\n",
    "        hidden_states = outputs.hidden_states[-6]  # n번째 레이어의 hidden states를 반환합니다.\n",
    "        loss = outputs.loss\n",
    "        return logits, loss, hidden_states\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "data_A = pd.read_csv(\"random_300.csv\")  # data set A 파일명에 맞게 수정\n",
    "data_B = pd.read_csv(\"infected.csv\")  # data set B 파일명에 맞게 수정\n",
    "# 모델 저장 경로\n",
    "model_path = \"Fine_tuned_epoch10.pt\"\n",
    "\n",
    "# X_train, Y_train 생성\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for index, row in data_A.iterrows():  # 중복 제거를 하지 않고 원본 데이터 사용\n",
    "    patient_id = row[\"ID\"]\n",
    "    patient_info = [str(row[column]) for column in data_A.columns if column != \"ID\" and column != \"DESCRIPTION\"]\n",
    "    symptoms = \", \".join(data_A[data_A[\"ID\"] == patient_id][\"DESCRIPTION\"].tolist())\n",
    "    combined_info = \", \".join(patient_info) + \", \" + symptoms\n",
    "    X_train.append(combined_info)\n",
    "    if patient_id in data_B.values:\n",
    "        Y_train.append(1)\n",
    "    else:\n",
    "        Y_train.append(0)\n",
    "\n",
    "print(\"X_train\\n\", X_train[:10])\n",
    "print(\"Y_train\\n\", Y_train[:10])\n",
    "        \n",
    "# BERT 토크나이저 및 모델 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# 모델이 이미 저장되어 있는지 확인하고, 저장된 모델이 있으면 불러오고 없으면 새로운 모델 생성\n",
    "if os.path.exists(model_path):\n",
    "    # 저장된 모델이 있을 경우 불러오기\n",
    "    model = CustomBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(\"Pre-train model loaded.\")\n",
    "else:\n",
    "    # 저장된 모델이 없을 경우 새로운 모델 생성\n",
    "    model = CustomBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "    print(\"New model generated.\")\n",
    "\n",
    "# 입력 데이터를 BERT의 입력 형식으로 변환\n",
    "max_len = 128  # 입력 시퀀스의 최대 길이\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for info in X_train:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        info,                         # 환자 정보 및 증상\n",
    "                        add_special_tokens = True,    # [CLS], [SEP] 토큰 추가\n",
    "                        max_length = max_len,         # 최대 길이 지정\n",
    "                        pad_to_max_length = True,     # 패딩을 추가하여 최대 길이로 맞춤\n",
    "                        return_attention_mask = True, # 어텐션 마스크 생성\n",
    "                        return_tensors = 'pt',        # PyTorch 텐서로 반환\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(Y_train)\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# 데이터로더 생성\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# 모델을 GPU로 이동\n",
    "model.to(device)\n",
    "\n",
    "# 모델 평가\n",
    "model.eval()\n",
    "val_accuracy = 0\n",
    "hidden_states_list = []  # 평가할 때 hidden state를 저장할 리스트\n",
    "for batch in dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    inputs = {'input_ids': batch[0],\n",
    "              'attention_mask': batch[1],\n",
    "              'labels': batch[2]}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs[0]  # logits가 outputs의 첫 번째 값입니다.\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = inputs['labels'].cpu().numpy()\n",
    "    val_accuracy += (logits.argmax(axis=1) == label_ids).mean().item()\n",
    "    # hidden state를 저장합니다.\n",
    "    hidden_states = outputs[2]\n",
    "    hidden_states_list.append(hidden_states)\n",
    "hidden_states_concat = torch.cat(hidden_states_list, dim=0)\n",
    "hidden_states_concat = hidden_states_concat[:, 0, :].cpu().detach().numpy()\n",
    "hidden_states_df = pd.DataFrame(hidden_states_concat)\n",
    "hidden_states_df.to_csv(\"Client_smashed_data_epoch10.csv\", index=False)\n",
    "\n",
    "print(f'Validation Accuracy: {val_accuracy / len(dataloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "423f678a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For file: Client_smashed_data_epoch1.csv\n",
      "Accuracy: 1.0\n",
      "Successful Mean Distance: 2.5438276577984817\n",
      "Unsuccessful Mean Distance: 4.752387982648165\n",
      "Successful Distance Variance: 0.3913100377899218\n",
      "Unsuccessful Distance Variance: 0.9184424409806703\n",
      "Success Indices: [(1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (146, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 1), (153, 1), (154, 1), (155, 1), (156, 1), (157, 1), (158, 1), (159, 1), (160, 1), (161, 1), (162, 1), (163, 1), (164, 1), (165, 1), (166, 1), (167, 1), (168, 1), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (181, 1), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1), (188, 1), (189, 1), (190, 1), (191, 1), (192, 1), (193, 1), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 1), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (212, 1), (213, 1), (214, 1), (215, 1), (216, 1), (217, 1), (218, 1), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 1), (236, 1), (237, 1), (238, 1), (239, 1), (240, 1), (241, 1), (242, 1), (243, 1), (244, 1), (245, 1), (246, 1), (247, 1), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1), (259, 1), (260, 1), (261, 1), (262, 1), (263, 1), (264, 1), (265, 1), (266, 1), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 1), (273, 1), (274, 1), (275, 1), (276, 1), (277, 1), (278, 1), (279, 1), (280, 1), (281, 1), (282, 1), (283, 1), (284, 1), (285, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (295, 1), (296, 1), (297, 1), (298, 1), (299, 1), (300, 1)]\n",
      "Success Ranks Count:\n",
      "Rank 1: 300 successes\n",
      "Rank 2: 0 successes\n",
      "Rank 3: 0 successes\n",
      "Rank 4: 0 successes\n",
      "Rank 5: 0 successes\n",
      "\n",
      "For file: Client_smashed_data_epoch2.csv\n",
      "Accuracy: 0.9966666666666667\n",
      "Successful Mean Distance: 3.1025664334792236\n",
      "Unsuccessful Mean Distance: 4.959722648477188\n",
      "Successful Distance Variance: 0.5532915246414616\n",
      "Unsuccessful Distance Variance: 0.8741751199097112\n",
      "Success Indices: [(1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 3), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 2), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 2), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (146, 2), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 1), (153, 1), (154, 1), (155, 1), (156, 1), (157, 1), (158, 3), (159, 1), (160, 1), (161, 1), (162, 1), (163, 1), (164, 1), (165, 1), (166, 1), (167, 1), (168, 1), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (181, 1), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1), (188, 1), (189, 1), (190, 1), (191, 1), (192, 1), (193, 1), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 1), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (212, 1), (213, 1), (214, 1), (215, 1), (217, 1), (218, 2), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 2), (236, 1), (237, 1), (238, 1), (239, 1), (240, 1), (241, 1), (242, 1), (243, 1), (244, 1), (245, 1), (246, 1), (247, 1), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1), (259, 1), (260, 1), (261, 1), (262, 1), (263, 1), (264, 1), (265, 1), (266, 1), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 1), (273, 1), (274, 1), (275, 1), (276, 1), (277, 1), (278, 1), (279, 1), (280, 1), (281, 1), (282, 1), (283, 1), (284, 1), (285, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (295, 1), (296, 1), (297, 2), (298, 1), (299, 1), (300, 1)]\n",
      "Success Ranks Count:\n",
      "Rank 1: 291 successes\n",
      "Rank 2: 6 successes\n",
      "Rank 3: 2 successes\n",
      "Rank 4: 0 successes\n",
      "Rank 5: 0 successes\n",
      "\n",
      "For file: Client_smashed_data_epoch3.csv\n",
      "Accuracy: 0.9933333333333333\n",
      "Successful Mean Distance: 3.635302257871565\n",
      "Unsuccessful Mean Distance: 5.196970303185741\n",
      "Successful Distance Variance: 0.7425112362627379\n",
      "Unsuccessful Distance Variance: 0.8854588790026864\n",
      "Success Indices: [(1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 4), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 3), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 2), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 2), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 5), (115, 1), (116, 1), (117, 1), (118, 2), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 2), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (146, 4), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 2), (153, 1), (154, 1), (155, 1), (156, 1), (157, 1), (159, 1), (160, 1), (161, 1), (162, 1), (163, 1), (164, 2), (165, 1), (166, 1), (167, 1), (168, 1), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (181, 1), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1), (188, 1), (189, 1), (190, 1), (191, 1), (192, 2), (193, 1), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 2), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (212, 3), (213, 1), (214, 1), (215, 1), (217, 1), (218, 4), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 2), (236, 1), (237, 1), (238, 1), (239, 1), (240, 1), (241, 1), (242, 1), (243, 1), (244, 1), (245, 1), (246, 1), (247, 2), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1), (259, 1), (260, 1), (261, 1), (262, 5), (263, 1), (264, 1), (265, 1), (266, 1), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 1), (273, 1), (274, 1), (275, 1), (276, 1), (277, 1), (278, 1), (279, 1), (280, 1), (281, 1), (282, 1), (283, 4), (284, 1), (285, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (295, 1), (296, 1), (297, 3), (298, 1), (299, 1), (300, 1)]\n",
      "Success Ranks Count:\n",
      "Rank 1: 279 successes\n",
      "Rank 2: 10 successes\n",
      "Rank 3: 3 successes\n",
      "Rank 4: 4 successes\n",
      "Rank 5: 2 successes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For file: Client_smashed_data_epoch4.csv\n",
      "Accuracy: 0.97\n",
      "Successful Mean Distance: 3.7721809052998925\n",
      "Unsuccessful Mean Distance: 5.255876781964985\n",
      "Successful Distance Variance: 0.7664979070345245\n",
      "Unsuccessful Distance Variance: 0.8818015841531784\n",
      "Success Indices: [(1, 1), (2, 1), (3, 2), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 3), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 5), (51, 1), (52, 2), (53, 1), (54, 1), (55, 2), (56, 1), (57, 1), (58, 2), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 4), (79, 1), (80, 1), (81, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 5), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 5), (115, 1), (116, 1), (117, 1), (118, 2), (119, 2), (120, 1), (121, 1), (122, 1), (123, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 2), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 2), (153, 1), (154, 1), (155, 1), (156, 1), (157, 1), (159, 1), (160, 1), (161, 1), (162, 2), (163, 1), (164, 4), (165, 1), (166, 1), (167, 1), (168, 1), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (181, 3), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1), (188, 1), (189, 2), (190, 1), (191, 1), (192, 2), (193, 1), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 2), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (212, 5), (213, 1), (214, 1), (215, 1), (217, 1), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 2), (236, 1), (237, 1), (238, 1), (239, 1), (240, 1), (241, 1), (242, 1), (243, 1), (244, 1), (245, 1), (246, 1), (247, 3), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1), (259, 2), (260, 1), (261, 1), (263, 2), (264, 1), (265, 1), (266, 1), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 1), (273, 1), (274, 1), (275, 1), (276, 1), (277, 1), (278, 1), (279, 1), (280, 3), (281, 1), (282, 1), (283, 4), (284, 1), (285, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (295, 2), (296, 1), (298, 1), (299, 1), (300, 1)]\n",
      "Success Ranks Count:\n",
      "Rank 1: 264 successes\n",
      "Rank 2: 16 successes\n",
      "Rank 3: 4 successes\n",
      "Rank 4: 3 successes\n",
      "Rank 5: 4 successes\n",
      "\n",
      "For file: Client_smashed_data_epoch5.csv\n",
      "Accuracy: 0.9466666666666667\n",
      "Successful Mean Distance: 3.9275727433970022\n",
      "Unsuccessful Mean Distance: 5.288877888998066\n",
      "Successful Distance Variance: 0.8335235974660324\n",
      "Unsuccessful Distance Variance: 0.8906101980485053\n",
      "Success Indices: [(1, 1), (2, 1), (3, 2), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 3), (20, 1), (21, 2), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (38, 1), (39, 2), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 2), (56, 1), (57, 1), (58, 2), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 2), (71, 1), (72, 1), (73, 2), (74, 1), (75, 1), (76, 1), (77, 1), (79, 1), (80, 3), (81, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 5), (89, 2), (90, 2), (91, 2), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 2), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (115, 1), (116, 1), (117, 2), (118, 2), (119, 2), (120, 1), (121, 1), (122, 1), (123, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 3), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 2), (153, 1), (154, 1), (155, 1), (156, 2), (157, 1), (159, 1), (160, 1), (161, 1), (162, 2), (163, 1), (165, 1), (166, 1), (167, 1), (168, 3), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (181, 5), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1), (188, 2), (189, 5), (190, 1), (191, 1), (192, 4), (193, 1), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 2), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (213, 1), (214, 1), (215, 1), (217, 1), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 5), (236, 1), (237, 1), (238, 1), (239, 1), (240, 1), (241, 1), (242, 1), (243, 1), (244, 1), (245, 1), (246, 1), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1), (259, 2), (260, 1), (261, 1), (263, 3), (264, 1), (265, 1), (266, 4), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 1), (273, 1), (274, 1), (275, 1), (276, 1), (277, 1), (278, 1), (279, 1), (280, 4), (281, 1), (282, 1), (283, 4), (284, 1), (285, 2), (286, 1), (287, 2), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (295, 1), (296, 1), (298, 1), (299, 1), (300, 1)]\n",
      "Success Ranks Count:\n",
      "Rank 1: 249 successes\n",
      "Rank 2: 22 successes\n",
      "Rank 3: 5 successes\n",
      "Rank 4: 4 successes\n",
      "Rank 5: 4 successes\n",
      "\n",
      "For file: Client_smashed_data_epoch6.csv\n",
      "Accuracy: 0.9633333333333334\n",
      "Successful Mean Distance: 3.592548570637081\n",
      "Unsuccessful Mean Distance: 5.132982157990792\n",
      "Successful Distance Variance: 0.7145128221809622\n",
      "Unsuccessful Distance Variance: 0.8919782881477633\n",
      "Success Indices: [(1, 1), (2, 1), (3, 2), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 3), (20, 1), (21, 2), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 2), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (79, 1), (80, 1), (81, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 2), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 5), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 5), (115, 1), (116, 1), (117, 1), (118, 2), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 3), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 2), (153, 1), (154, 1), (155, 1), (156, 1), (157, 1), (159, 1), (160, 1), (161, 1), (162, 2), (163, 1), (165, 1), (166, 1), (167, 1), (168, 1), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (181, 3), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1), (188, 2), (189, 1), (190, 1), (191, 1), (192, 2), (193, 1), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 2), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (212, 4), (213, 1), (214, 1), (215, 1), (217, 1), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 2), (236, 1), (237, 1), (238, 1), (239, 1), (240, 1), (241, 1), (242, 1), (243, 1), (244, 1), (245, 1), (246, 1), (247, 4), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1), (259, 2), (260, 1), (261, 1), (263, 3), (264, 1), (265, 1), (266, 2), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 1), (273, 1), (274, 1), (275, 1), (276, 1), (277, 1), (278, 1), (279, 1), (280, 3), (281, 1), (282, 1), (283, 2), (284, 1), (285, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (295, 1), (296, 1), (298, 1), (299, 1), (300, 1)]\n",
      "Success Ranks Count:\n",
      "Rank 1: 266 successes\n",
      "Rank 2: 14 successes\n",
      "Rank 3: 5 successes\n",
      "Rank 4: 2 successes\n",
      "Rank 5: 2 successes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For file: Client_smashed_data_epoch7.csv\n",
      "Accuracy: 0.9433333333333334\n",
      "Successful Mean Distance: 3.7758467261400006\n",
      "Unsuccessful Mean Distance: 5.186008885027237\n",
      "Successful Distance Variance: 0.8047412555404886\n",
      "Unsuccessful Distance Variance: 0.8930949015315061\n",
      "Success Indices: [(1, 1), (2, 1), (3, 2), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 3), (20, 1), (21, 2), (22, 1), (23, 2), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 3), (35, 1), (36, 1), (37, 1), (38, 1), (39, 2), (40, 1), (41, 1), (42, 1), (43, 1), (44, 2), (45, 1), (46, 1), (47, 1), (48, 1), (49, 2), (51, 1), (52, 1), (53, 1), (54, 1), (55, 2), (56, 1), (57, 1), (58, 2), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (79, 1), (80, 3), (81, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (89, 2), (90, 2), (91, 2), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (115, 1), (116, 1), (117, 2), (118, 2), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 3), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 2), (153, 1), (154, 2), (155, 1), (156, 2), (157, 1), (159, 1), (160, 1), (161, 1), (162, 4), (163, 1), (165, 1), (166, 1), (167, 1), (168, 3), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1), (188, 2), (189, 2), (190, 1), (191, 1), (192, 4), (193, 4), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 2), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (213, 1), (214, 1), (215, 1), (217, 1), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 2), (236, 1), (237, 1), (238, 2), (239, 1), (240, 1), (241, 1), (242, 1), (243, 1), (244, 1), (245, 1), (246, 1), (247, 5), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1), (259, 2), (260, 1), (261, 1), (263, 3), (264, 1), (265, 1), (266, 3), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 1), (273, 1), (274, 1), (275, 1), (276, 1), (277, 1), (278, 1), (279, 1), (280, 3), (281, 1), (282, 1), (284, 1), (285, 2), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (295, 2), (296, 1), (298, 1), (299, 1), (300, 1)]\n",
      "Success Ranks Count:\n",
      "Rank 1: 247 successes\n",
      "Rank 2: 24 successes\n",
      "Rank 3: 8 successes\n",
      "Rank 4: 3 successes\n",
      "Rank 5: 1 successes\n",
      "\n",
      "For file: Client_smashed_data_epoch8.csv\n",
      "Accuracy: 0.9133333333333333\n",
      "Successful Mean Distance: 4.039167591839215\n",
      "Unsuccessful Mean Distance: 5.3654474581348355\n",
      "Successful Distance Variance: 0.9847253832760521\n",
      "Unsuccessful Distance Variance: 0.9019249944647324\n",
      "Success Indices: [(1, 1), (2, 1), (3, 2), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (20, 1), (21, 2), (22, 1), (23, 3), (24, 1), (25, 3), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 4), (35, 1), (36, 1), (37, 1), (38, 1), (39, 4), (40, 1), (41, 1), (42, 1), (43, 1), (44, 2), (45, 1), (46, 1), (47, 1), (48, 1), (49, 3), (51, 1), (52, 1), (53, 1), (54, 1), (55, 3), (56, 1), (57, 1), (58, 2), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 2), (71, 1), (72, 1), (73, 2), (74, 1), (75, 1), (76, 1), (77, 1), (79, 1), (80, 3), (81, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (89, 2), (90, 5), (91, 4), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (115, 2), (116, 1), (117, 2), (118, 2), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (135, 1), (136, 2), (137, 1), (138, 1), (140, 1), (141, 5), (142, 1), (143, 1), (144, 1), (145, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 2), (153, 1), (154, 2), (155, 1), (156, 3), (157, 2), (159, 1), (160, 1), (161, 1), (163, 1), (165, 1), (166, 1), (167, 1), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1), (189, 2), (190, 1), (191, 1), (193, 4), (194, 1), (195, 1), (196, 1), (197, 1), (198, 3), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 2), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (213, 2), (214, 1), (215, 1), (217, 1), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 2), (231, 1), (232, 1), (233, 1), (234, 1), (235, 4), (236, 1), (237, 1), (238, 1), (239, 1), (240, 1), (241, 1), (242, 2), (243, 1), (244, 1), (245, 1), (246, 1), (247, 4), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1), (259, 3), (260, 1), (261, 1), (263, 2), (264, 1), (265, 1), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 1), (273, 1), (274, 1), (275, 1), (276, 1), (277, 2), (278, 1), (279, 2), (281, 1), (282, 1), (283, 4), (284, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (295, 1), (296, 1), (298, 1), (299, 1), (300, 1)]\n",
      "Success Ranks Count:\n",
      "Rank 1: 235 successes\n",
      "Rank 2: 22 successes\n",
      "Rank 3: 8 successes\n",
      "Rank 4: 7 successes\n",
      "Rank 5: 2 successes\n",
      "\n",
      "For file: Client_smashed_data_epoch9.csv\n",
      "Accuracy: 0.8233333333333334\n",
      "Successful Mean Distance: 4.176936990425053\n",
      "Unsuccessful Mean Distance: 5.368925121466513\n",
      "Successful Distance Variance: 0.9345151183342575\n",
      "Unsuccessful Distance Variance: 0.8738455866559391\n",
      "Success Indices: [(1, 1), (2, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2), (11, 1), (12, 1), (13, 1), (14, 2), (15, 1), (16, 1), (17, 1), (18, 1), (20, 1), (21, 3), (22, 1), (23, 4), (24, 1), (25, 3), (26, 1), (27, 2), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (36, 1), (37, 1), (38, 2), (40, 2), (42, 1), (43, 1), (44, 2), (45, 1), (46, 1), (47, 1), (48, 1), (51, 1), (52, 1), (53, 1), (54, 1), (56, 1), (57, 1), (58, 3), (59, 3), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (71, 1), (72, 1), (73, 3), (74, 1), (75, 1), (76, 1), (77, 1), (79, 1), (80, 4), (81, 1), (83, 1), (84, 1), (85, 1), (86, 2), (87, 1), (89, 3), (92, 1), (93, 1), (94, 1), (95, 1), (96, 2), (97, 1), (98, 2), (99, 1), (100, 2), (101, 3), (102, 1), (103, 1), (104, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (115, 4), (116, 1), (117, 2), (118, 4), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 3), (135, 1), (137, 1), (138, 1), (140, 1), (142, 1), (143, 1), (144, 1), (145, 2), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 4), (153, 1), (154, 5), (159, 1), (160, 4), (161, 1), (163, 1), (165, 1), (166, 1), (167, 1), (169, 1), (170, 1), (171, 2), (172, 1), (173, 1), (174, 2), (175, 1), (176, 1), (177, 1), (178, 1), (179, 2), (180, 1), (182, 1), (183, 1), (184, 2), (185, 1), (186, 1), (187, 1), (190, 1), (191, 1), (194, 1), (195, 1), (196, 2), (197, 1), (199, 1), (200, 1), (201, 1), (202, 4), (203, 1), (204, 1), (205, 1), (206, 4), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (214, 3), (217, 2), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (228, 1), (229, 1), (231, 2), (232, 1), (233, 1), (234, 1), (236, 1), (237, 1), (238, 2), (239, 4), (240, 1), (241, 1), (242, 2), (243, 5), (244, 1), (245, 1), (246, 1), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1), (260, 1), (261, 1), (264, 1), (265, 1), (267, 1), (268, 1), (269, 1), (270, 1), (271, 4), (272, 1), (273, 1), (274, 1), (275, 1), (276, 5), (278, 1), (279, 3), (281, 1), (282, 1), (283, 3), (284, 1), (286, 1), (287, 2), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 2), (295, 1), (296, 1), (298, 1), (299, 1), (300, 1)]\n",
      "Success Ranks Count:\n",
      "Rank 1: 199 successes\n",
      "Rank 2: 24 successes\n",
      "Rank 3: 11 successes\n",
      "Rank 4: 10 successes\n",
      "Rank 5: 3 successes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For file: Client_smashed_data_epoch10.csv\n",
      "Accuracy: 0.7966666666666666\n",
      "Successful Mean Distance: 4.227534181175542\n",
      "Unsuccessful Mean Distance: 5.476350256029426\n",
      "Successful Distance Variance: 1.0794834746356072\n",
      "Unsuccessful Distance Variance: 0.8850476238873897\n",
      "Success Indices: [(1, 1), (2, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 4), (15, 1), (16, 1), (17, 1), (18, 1), (20, 1), (21, 3), (22, 1), (23, 4), (24, 1), (25, 3), (26, 1), (27, 3), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (36, 1), (37, 1), (38, 4), (40, 1), (42, 1), (43, 1), (44, 2), (45, 1), (46, 2), (47, 1), (48, 3), (51, 1), (52, 1), (53, 1), (54, 1), (56, 1), (57, 1), (58, 2), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (71, 1), (72, 1), (73, 2), (74, 1), (75, 1), (76, 1), (77, 1), (79, 1), (80, 4), (81, 1), (83, 1), (84, 1), (85, 5), (86, 4), (87, 1), (89, 5), (92, 1), (93, 1), (94, 1), (95, 1), (96, 2), (97, 1), (98, 1), (99, 1), (100, 1), (101, 3), (102, 1), (103, 1), (104, 1), (106, 1), (107, 1), (108, 2), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (116, 1), (117, 2), (118, 2), (119, 1), (120, 1), (121, 5), (122, 1), (123, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 3), (132, 1), (133, 3), (135, 1), (137, 1), (138, 1), (140, 1), (142, 2), (143, 1), (144, 1), (145, 2), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (153, 1), (154, 4), (159, 1), (160, 2), (161, 1), (163, 1), (165, 1), (166, 1), (167, 1), (169, 1), (170, 3), (171, 4), (172, 1), (173, 1), (174, 3), (175, 1), (176, 1), (177, 1), (178, 1), (179, 3), (180, 1), (182, 1), (183, 1), (184, 2), (185, 1), (186, 1), (187, 1), (190, 1), (191, 1), (194, 1), (195, 1), (196, 3), (197, 1), (199, 1), (200, 1), (201, 2), (202, 4), (203, 1), (204, 1), (205, 1), (206, 2), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (214, 3), (217, 4), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (228, 1), (229, 1), (231, 2), (232, 1), (233, 1), (234, 1), (236, 1), (237, 1), (238, 2), (239, 4), (240, 1), (241, 1), (242, 3), (244, 3), (245, 1), (246, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 4), (256, 1), (257, 1), (258, 1), (260, 1), (261, 1), (264, 1), (265, 1), (267, 1), (268, 1), (269, 1), (270, 1), (272, 1), (273, 1), (274, 1), (275, 1), (278, 1), (279, 3), (281, 3), (282, 1), (283, 1), (284, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 2), (295, 1), (296, 1), (298, 1), (299, 1), (300, 1)]\n",
      "Success Ranks Count:\n",
      "Rank 1: 191 successes\n",
      "Rank 2: 18 successes\n",
      "Rank 3: 16 successes\n",
      "Rank 4: 11 successes\n",
      "Rank 5: 3 successes\n"
     ]
    }
   ],
   "source": [
    "# 유클리드 거리 유사도\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def calculate_accuracy_and_distance(client_file, dictionary_file, original_file_client, original_file_dictionary, n=5):\n",
    "    # 변환된 파일을 읽어옵니다.\n",
    "    client_data = pd.read_csv(client_file)\n",
    "    dictionary_data = pd.read_csv(dictionary_file)\n",
    "    \n",
    "    # 원본 파일을 읽어옵니다.\n",
    "    original_client_data = pd.read_csv(original_file_client)\n",
    "    original_dictionary_data = pd.read_csv(original_file_dictionary)\n",
    "    \n",
    "    # 데이터 포인트 간의 유클리드 거리를 계산합니다.\n",
    "    distances = euclidean_distances(client_data.values, dictionary_data.values)\n",
    "    \n",
    "    # Top@n 유사도를 찾습니다.\n",
    "    topn_similarities = np.argsort(distances, axis=1)[:, :n]\n",
    "    topn_values = np.sort(distances, axis=1)[:, :n]\n",
    "    \n",
    "    # 모든 결과를 출력하고 정확도를 계산합니다.\n",
    "    successful_distances = []\n",
    "    unsuccessful_distances = []\n",
    "    successes = 0\n",
    "    success_indices = []  # 성공한 인덱스를 저장할 리스트\n",
    "    success_ranks_count = {rank: 0 for rank in range(1, n+1)}  # 각 성공한 서버 측 랭크의 수를 저장할 딕셔너리\n",
    "    for i, (indices, scores) in enumerate(zip(topn_similarities, topn_values)):\n",
    "        \"\"\"print(f\"\\nTop {n} inferences for client {i + 1}:\")\"\"\"\n",
    "        for rank, (idx, score) in enumerate(zip(indices, scores), 1):\n",
    "            \"\"\"print(f\"Server {idx + 1} with distance {score}\")\"\"\"\n",
    "            if original_client_data.iloc[i].equals(original_dictionary_data.iloc[idx]):\n",
    "                successes += 1\n",
    "                successful_distances.append(score)\n",
    "                success_indices.append((i + 1, rank))  # 성공한 인덱스를 추가\n",
    "                success_ranks_count[rank] += 1  # 해당 랭크의 수를 증가시킴\n",
    "            else:\n",
    "                unsuccessful_distances.append(score)\n",
    "        if successes == 0:\n",
    "            print(\"No successful match found.\")\n",
    "    \n",
    "    # 정확도 계산\n",
    "    accuracy = successes / len(client_data)\n",
    "    \n",
    "    # 성공적으로 일치하는 데이터 포인트와 클라이언트 데이터 포인트, 그리고 일치하지 않는 데이터 포인트와 클라이언트 데이터 포인트 간의 평균 거리를 계산합니다.\n",
    "    successful_mean_distance = np.mean(successful_distances)\n",
    "    unsuccessful_mean_distance = np.mean(unsuccessful_distances)\n",
    "    \n",
    "    # 평균 거리의 분산 계산\n",
    "    successful_distance_variance = np.var(successful_distances)\n",
    "    unsuccessful_distance_variance = np.var(unsuccessful_distances)\n",
    "    \n",
    "    return accuracy, successful_mean_distance, unsuccessful_mean_distance, success_indices, successful_distance_variance, unsuccessful_distance_variance, success_ranks_count\n",
    "\n",
    "# 변환된 파일 경로\n",
    "dictionary_file = \"Dictionary_smashed_data.csv\"\n",
    "\n",
    "# 원본 파일 경로\n",
    "original_file_client = \"random_300.csv\"\n",
    "original_file_dictionary = \"random_500.csv\"\n",
    "\n",
    "# Top n 설정\n",
    "n = 5\n",
    "\n",
    "# 정확도 계산 및 평균 거리 계산\n",
    "for i in range(1, 11):\n",
    "    client_file = f'Client_smashed_data_epoch{i}.csv'\n",
    "    accuracy, successful_mean_distance, unsuccessful_mean_distance, success_indices, successful_distance_variance, unsuccessful_distance_variance, success_ranks_count = calculate_accuracy_and_distance(client_file, dictionary_file, original_file_client, original_file_dictionary, n)\n",
    "\n",
    "    print(\"\\nFor file:\", client_file)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Successful Mean Distance:\", successful_mean_distance)\n",
    "    print(\"Unsuccessful Mean Distance:\", unsuccessful_mean_distance)\n",
    "\n",
    "    # 분산 출력\n",
    "    print(\"Successful Distance Variance:\", successful_distance_variance)\n",
    "    print(\"Unsuccessful Distance Variance:\", unsuccessful_distance_variance)\n",
    "\n",
    "    # 성공한 인덱스들을 출력합니다.\n",
    "    print(\"Success Indices:\", success_indices)\n",
    "\n",
    "    # 각 성공한 서버 측 랭크의 수를 출력합니다.\n",
    "    print(\"Success Ranks Count:\")\n",
    "    for rank, count in success_ranks_count.items():\n",
    "        print(f\"Rank {rank}: {count} successes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c1ba6754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 1.0\n",
      "Successful Mean Similarity: 0.5832581604617318\n",
      "Unsuccessful Mean Similarity: 0.6006523540635847\n",
      "Successful Similarity Variance: 0.0012225691791490979\n",
      "Unsuccessful Similarity Variance: 0.0012625286762643782\n",
      "Success Indices: [(1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (146, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 1), (153, 1), (154, 1), (155, 1), (156, 1), (157, 1), (158, 1), (159, 1), (160, 1), (161, 1), (162, 1), (163, 1), (164, 1), (165, 1), (166, 1), (167, 1), (168, 1), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (181, 1), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1), (188, 1), (189, 1), (190, 1), (191, 1), (192, 1), (193, 1), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 1), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (212, 1), (213, 1), (214, 1), (215, 1), (216, 1), (217, 1), (218, 1), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 1), (236, 1), (237, 1), (238, 1), (239, 1), (240, 1), (241, 1), (242, 1), (243, 1), (244, 1), (245, 1), (246, 1), (247, 1), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1), (259, 1), (260, 1), (261, 1), (262, 1), (263, 1), (264, 1), (265, 1), (266, 1), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 1), (273, 1), (274, 1), (275, 1), (276, 1), (277, 1), (278, 1), (279, 1), (280, 1), (281, 1), (282, 1), (283, 1), (284, 1), (285, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (295, 1), (296, 1), (297, 1), (298, 1), (299, 1), (300, 1)]\n",
      "\n",
      "Accuracy: 0.9966666666666667\n",
      "Successful Mean Similarity: 0.5854060880436024\n",
      "Unsuccessful Mean Similarity: 0.602944568704819\n",
      "Successful Similarity Variance: 0.001241862159089285\n",
      "Unsuccessful Similarity Variance: 0.0012912672915085781\n",
      "Success Indices: [(1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 3), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 2), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 2), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (146, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 1), (153, 1), (154, 1), (155, 1), (156, 1), (157, 1), (158, 3), (159, 1), (160, 1), (161, 1), (162, 1), (163, 1), (164, 1), (165, 1), (166, 1), (167, 1), (168, 1), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (181, 1), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1), (188, 1), (189, 1), (190, 1), (191, 1), (192, 1), (193, 1), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 1), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (212, 1), (213, 1), (214, 1), (215, 1), (217, 1), (218, 2), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 2), (236, 1), (237, 1), (238, 1), (239, 1), (240, 1), (241, 1), (242, 1), (243, 1), (244, 1), (245, 1), (246, 1), (247, 1), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1), (259, 1), (260, 1), (261, 1), (262, 1), (263, 1), (264, 1), (265, 1), (266, 1), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 1), (273, 1), (274, 1), (275, 1), (276, 1), (277, 1), (278, 1), (279, 1), (280, 1), (281, 1), (282, 1), (283, 1), (284, 1), (285, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (295, 1), (296, 1), (297, 2), (298, 1), (299, 1), (300, 1)]\n",
      "\n",
      "Accuracy: 0.9966666666666667\n",
      "Successful Mean Similarity: 0.5899450535221891\n",
      "Unsuccessful Mean Similarity: 0.606914375999155\n",
      "Successful Similarity Variance: 0.0013863477295016269\n",
      "Unsuccessful Similarity Variance: 0.0014288342568946376\n",
      "Success Indices: [(1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 4), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 3), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 2), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 2), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 5), (115, 1), (116, 1), (117, 1), (118, 2), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 2), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (146, 4), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 2), (153, 1), (154, 1), (155, 1), (156, 1), (157, 1), (158, 5), (159, 1), (160, 1), (161, 1), (162, 1), (163, 1), (164, 2), (165, 1), (166, 1), (167, 1), (168, 1), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (181, 1), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1), (188, 1), (189, 1), (190, 1), (191, 1), (192, 2), (193, 1), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 1), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (212, 3), (213, 1), (214, 1), (215, 1), (217, 1), (218, 4), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 2), (236, 1), (237, 1), (238, 1), (239, 1), (240, 1), (241, 1), (242, 1), (243, 1), (244, 1), (245, 1), (246, 1), (247, 2), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1), (259, 1), (260, 1), (261, 1), (262, 3), (263, 1), (264, 1), (265, 1), (266, 1), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 1), (273, 1), (274, 1), (275, 1), (276, 1), (277, 1), (278, 1), (279, 1), (280, 1), (281, 1), (282, 1), (283, 4), (284, 1), (285, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (295, 1), (296, 1), (297, 3), (298, 1), (299, 1), (300, 1)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.97\n",
      "Successful Mean Similarity: 0.5886010819282088\n",
      "Unsuccessful Mean Similarity: 0.6058528250861634\n",
      "Successful Similarity Variance: 0.0014356020578969704\n",
      "Unsuccessful Similarity Variance: 0.0014421758645175344\n",
      "Success Indices: [(1, 1), (2, 1), (3, 2), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 3), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 5), (51, 1), (52, 2), (53, 1), (54, 1), (55, 2), (56, 1), (57, 1), (58, 2), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 4), (79, 1), (80, 1), (81, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 5), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 5), (115, 1), (116, 1), (117, 1), (118, 2), (119, 2), (120, 1), (121, 1), (122, 1), (123, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 2), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 2), (153, 1), (154, 1), (155, 1), (156, 1), (157, 1), (159, 1), (160, 1), (161, 1), (162, 2), (163, 1), (164, 4), (165, 1), (166, 1), (167, 1), (168, 1), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (181, 3), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1), (188, 1), (189, 2), (190, 1), (191, 1), (192, 2), (193, 1), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 2), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (212, 5), (213, 1), (214, 1), (215, 1), (217, 1), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 2), (236, 1), (237, 1), (238, 1), (239, 1), (240, 1), (241, 1), (242, 1), (243, 1), (244, 1), (245, 1), (246, 1), (247, 3), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1), (259, 2), (260, 1), (261, 1), (263, 2), (264, 1), (265, 1), (266, 1), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 1), (273, 1), (274, 1), (275, 1), (276, 1), (277, 1), (278, 1), (279, 1), (280, 3), (281, 1), (282, 1), (283, 4), (284, 1), (285, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (295, 1), (296, 1), (298, 1), (299, 1), (300, 1)]\n",
      "\n",
      "Accuracy: 0.9466666666666667\n",
      "Successful Mean Similarity: 0.5850794477044842\n",
      "Unsuccessful Mean Similarity: 0.6024386979883778\n",
      "Successful Similarity Variance: 0.0014525420556619599\n",
      "Unsuccessful Similarity Variance: 0.001437524823526834\n",
      "Success Indices: [(1, 1), (2, 1), (3, 2), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 3), (20, 1), (21, 2), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (38, 1), (39, 2), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 2), (56, 1), (57, 1), (58, 2), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 2), (71, 1), (72, 1), (73, 2), (74, 1), (75, 1), (76, 1), (77, 1), (79, 1), (80, 3), (81, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 5), (89, 2), (90, 2), (91, 2), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 2), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (115, 1), (116, 1), (117, 2), (118, 2), (119, 2), (120, 1), (121, 1), (122, 1), (123, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 4), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 2), (153, 1), (154, 2), (155, 1), (156, 2), (157, 1), (159, 1), (160, 2), (161, 1), (162, 2), (163, 1), (165, 1), (166, 1), (167, 1), (168, 3), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (181, 5), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1), (188, 2), (189, 4), (190, 1), (191, 1), (192, 5), (193, 1), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 2), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (213, 1), (214, 1), (215, 1), (217, 1), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 5), (236, 1), (237, 1), (238, 1), (239, 1), (240, 1), (241, 1), (242, 1), (243, 1), (244, 1), (245, 1), (246, 1), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1), (259, 2), (260, 1), (261, 1), (263, 3), (264, 1), (265, 1), (266, 4), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 1), (273, 1), (274, 1), (275, 1), (276, 1), (277, 1), (278, 1), (279, 1), (280, 5), (281, 1), (282, 1), (283, 4), (284, 1), (285, 2), (286, 1), (287, 2), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (295, 1), (296, 1), (298, 1), (299, 1), (300, 1)]\n",
      "\n",
      "Accuracy: 0.9633333333333334\n",
      "Successful Mean Similarity: 0.5829715616754731\n",
      "Unsuccessful Mean Similarity: 0.6010526909362691\n",
      "Successful Similarity Variance: 0.0014036701787603358\n",
      "Unsuccessful Similarity Variance: 0.001411180070117851\n",
      "Success Indices: [(1, 1), (2, 1), (3, 2), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 3), (20, 1), (21, 2), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 2), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (79, 1), (80, 1), (81, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 2), (90, 2), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 5), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 5), (115, 1), (116, 1), (117, 1), (118, 2), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 3), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 2), (153, 1), (154, 1), (155, 1), (156, 1), (157, 1), (159, 1), (160, 1), (161, 1), (162, 2), (163, 1), (165, 1), (166, 1), (167, 1), (168, 1), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (181, 3), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1), (188, 2), (189, 1), (190, 1), (191, 1), (192, 2), (193, 1), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 2), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (212, 4), (213, 1), (214, 1), (215, 1), (217, 1), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 2), (236, 1), (237, 1), (238, 1), (239, 1), (240, 1), (241, 1), (242, 1), (243, 1), (244, 1), (245, 1), (246, 1), (247, 4), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1), (259, 2), (260, 1), (261, 1), (263, 3), (264, 1), (265, 1), (266, 2), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 1), (273, 1), (274, 1), (275, 1), (276, 1), (277, 1), (278, 1), (279, 1), (280, 3), (281, 1), (282, 1), (283, 2), (284, 1), (285, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (295, 1), (296, 1), (298, 1), (299, 1), (300, 1)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9466666666666667\n",
      "Successful Mean Similarity: 0.5838258078427557\n",
      "Unsuccessful Mean Similarity: 0.6016367306093087\n",
      "Successful Similarity Variance: 0.0015067737042551124\n",
      "Unsuccessful Similarity Variance: 0.0014549954715700002\n",
      "Success Indices: [(1, 1), (2, 1), (3, 2), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 3), (20, 1), (21, 2), (22, 1), (23, 2), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 3), (35, 1), (36, 1), (37, 1), (38, 1), (39, 2), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 2), (51, 1), (52, 1), (53, 1), (54, 1), (55, 2), (56, 1), (57, 1), (58, 2), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (79, 1), (80, 3), (81, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (89, 2), (90, 2), (91, 2), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (115, 1), (116, 1), (117, 2), (118, 2), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 4), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 2), (153, 1), (154, 2), (155, 1), (156, 2), (157, 1), (159, 1), (160, 1), (161, 1), (162, 4), (163, 1), (165, 1), (166, 1), (167, 1), (168, 3), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1), (188, 2), (189, 2), (190, 1), (191, 1), (192, 4), (193, 4), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 2), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (213, 1), (214, 1), (215, 1), (217, 1), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 2), (236, 1), (237, 1), (238, 2), (239, 1), (240, 1), (241, 1), (242, 1), (243, 1), (244, 1), (245, 1), (246, 1), (247, 5), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1), (259, 2), (260, 1), (261, 1), (263, 3), (264, 1), (265, 1), (266, 3), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 1), (273, 1), (274, 1), (275, 1), (276, 1), (277, 1), (278, 1), (279, 1), (280, 3), (281, 1), (282, 1), (283, 4), (284, 1), (285, 2), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (295, 2), (296, 1), (298, 1), (299, 1), (300, 1)]\n",
      "\n",
      "Accuracy: 0.9133333333333333\n",
      "Successful Mean Similarity: 0.587685147585763\n",
      "Unsuccessful Mean Similarity: 0.606172708505594\n",
      "Successful Similarity Variance: 0.0017204740847982303\n",
      "Unsuccessful Similarity Variance: 0.0016358737027399332\n",
      "Success Indices: [(1, 1), (2, 1), (3, 2), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (20, 1), (21, 2), (22, 1), (23, 3), (24, 1), (25, 3), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 4), (35, 1), (36, 1), (37, 1), (38, 1), (39, 4), (40, 1), (41, 1), (42, 1), (43, 1), (44, 2), (45, 1), (46, 1), (47, 1), (48, 1), (49, 3), (51, 1), (52, 1), (53, 1), (54, 1), (55, 3), (56, 1), (57, 1), (58, 2), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 2), (71, 1), (72, 1), (73, 2), (74, 1), (75, 1), (76, 1), (77, 1), (79, 1), (80, 3), (81, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (89, 2), (90, 4), (91, 5), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (115, 2), (116, 1), (117, 2), (118, 2), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (135, 1), (136, 2), (137, 1), (138, 1), (140, 1), (141, 5), (142, 1), (143, 1), (144, 1), (145, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 2), (153, 1), (154, 2), (155, 1), (156, 3), (157, 2), (159, 1), (160, 1), (161, 1), (163, 1), (165, 1), (166, 1), (167, 1), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1), (189, 2), (190, 1), (191, 1), (193, 4), (194, 1), (195, 1), (196, 1), (197, 1), (198, 3), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 2), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (213, 2), (214, 1), (215, 1), (217, 1), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 2), (231, 1), (232, 1), (233, 1), (234, 1), (235, 4), (236, 1), (237, 1), (238, 1), (239, 1), (240, 1), (241, 1), (242, 2), (243, 1), (244, 1), (245, 1), (246, 1), (247, 5), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1), (259, 3), (260, 1), (261, 1), (263, 2), (264, 1), (265, 1), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 1), (273, 1), (274, 1), (275, 1), (276, 1), (277, 2), (278, 1), (279, 2), (281, 1), (282, 1), (283, 4), (284, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (295, 1), (296, 1), (298, 1), (299, 1), (300, 1)]\n",
      "\n",
      "Accuracy: 0.8233333333333334\n",
      "Successful Mean Similarity: 0.5809720180095543\n",
      "Unsuccessful Mean Similarity: 0.5991962441765714\n",
      "Successful Similarity Variance: 0.0014935671025925212\n",
      "Unsuccessful Similarity Variance: 0.00134893798687559\n",
      "Success Indices: [(1, 1), (2, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2), (11, 1), (12, 1), (13, 1), (14, 2), (15, 1), (16, 1), (17, 1), (18, 1), (20, 1), (21, 3), (22, 1), (23, 4), (24, 1), (25, 3), (26, 1), (27, 2), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (36, 1), (37, 1), (38, 2), (40, 1), (42, 1), (43, 1), (44, 2), (45, 1), (46, 1), (47, 1), (48, 1), (51, 1), (52, 1), (53, 1), (54, 1), (56, 1), (57, 1), (58, 3), (59, 3), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (71, 1), (72, 1), (73, 3), (74, 1), (75, 1), (76, 1), (77, 1), (79, 1), (80, 4), (81, 1), (83, 1), (84, 1), (85, 1), (86, 2), (87, 1), (89, 3), (92, 1), (93, 1), (94, 1), (95, 1), (96, 2), (97, 1), (98, 2), (99, 1), (100, 2), (101, 3), (102, 1), (103, 1), (104, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (115, 4), (116, 1), (117, 2), (118, 4), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 3), (135, 1), (137, 1), (138, 1), (140, 1), (142, 2), (143, 1), (144, 1), (145, 2), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 4), (153, 1), (154, 5), (159, 1), (160, 4), (161, 1), (163, 1), (165, 1), (166, 1), (167, 1), (169, 1), (170, 1), (171, 2), (172, 1), (173, 1), (174, 2), (175, 1), (176, 1), (177, 1), (178, 1), (179, 2), (180, 1), (182, 1), (183, 1), (184, 2), (185, 1), (186, 1), (187, 1), (190, 1), (191, 1), (194, 1), (195, 1), (196, 2), (197, 1), (199, 1), (200, 1), (201, 1), (202, 4), (203, 1), (204, 1), (205, 1), (206, 4), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (214, 3), (217, 2), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (228, 1), (229, 1), (231, 2), (232, 1), (233, 1), (234, 1), (236, 1), (237, 1), (238, 2), (239, 4), (240, 1), (241, 1), (242, 3), (243, 5), (244, 1), (245, 1), (246, 1), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 2), (256, 1), (257, 1), (258, 1), (260, 1), (261, 1), (264, 1), (265, 1), (267, 1), (268, 1), (269, 1), (270, 1), (271, 4), (272, 1), (273, 1), (274, 1), (275, 1), (276, 5), (278, 1), (279, 3), (281, 2), (282, 1), (283, 2), (284, 1), (286, 1), (287, 2), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 2), (295, 1), (296, 1), (298, 1), (299, 1), (300, 1)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7966666666666666\n",
      "Successful Mean Similarity: 0.5800813893160567\n",
      "Unsuccessful Mean Similarity: 0.5980569398248643\n",
      "Successful Similarity Variance: 0.0015849241088291696\n",
      "Unsuccessful Similarity Variance: 0.0014388448002513143\n",
      "Success Indices: [(1, 1), (2, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 4), (15, 1), (16, 1), (17, 1), (18, 1), (20, 1), (21, 3), (22, 1), (23, 4), (24, 1), (25, 3), (26, 1), (27, 3), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (36, 1), (37, 1), (38, 5), (40, 1), (42, 1), (43, 1), (44, 2), (45, 1), (46, 2), (47, 1), (48, 3), (51, 1), (52, 1), (53, 1), (54, 1), (56, 1), (57, 1), (58, 2), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (71, 1), (72, 1), (73, 2), (74, 1), (75, 1), (76, 1), (77, 1), (79, 1), (80, 4), (81, 1), (83, 1), (84, 1), (85, 5), (86, 4), (87, 1), (89, 5), (92, 1), (93, 1), (94, 1), (95, 1), (96, 2), (97, 1), (98, 1), (99, 1), (100, 1), (101, 3), (102, 1), (103, 1), (104, 1), (106, 1), (107, 1), (108, 3), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (116, 1), (117, 2), (118, 2), (119, 1), (120, 1), (121, 5), (122, 1), (123, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 3), (132, 1), (133, 3), (135, 1), (137, 1), (138, 1), (140, 1), (142, 2), (143, 1), (144, 1), (145, 2), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (153, 1), (154, 4), (159, 1), (160, 2), (161, 1), (163, 1), (165, 1), (166, 1), (167, 1), (169, 1), (170, 3), (171, 4), (172, 1), (173, 1), (174, 3), (175, 1), (176, 1), (177, 1), (178, 1), (179, 4), (180, 1), (182, 1), (183, 1), (184, 2), (185, 1), (186, 1), (187, 1), (190, 1), (191, 1), (194, 1), (195, 1), (196, 3), (197, 1), (199, 1), (200, 1), (201, 2), (202, 4), (203, 1), (204, 1), (205, 1), (206, 2), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (214, 3), (217, 4), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (228, 1), (229, 1), (231, 2), (232, 1), (233, 1), (234, 1), (236, 1), (237, 1), (238, 2), (239, 4), (240, 1), (241, 1), (242, 3), (244, 3), (245, 1), (246, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 4), (256, 1), (257, 1), (258, 1), (260, 1), (261, 1), (264, 1), (265, 1), (267, 1), (268, 1), (269, 1), (270, 1), (272, 1), (273, 1), (274, 1), (275, 1), (278, 1), (279, 3), (281, 3), (282, 1), (283, 1), (284, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 2), (295, 1), (296, 1), (298, 1), (299, 1), (300, 1)]\n"
     ]
    }
   ],
   "source": [
    "# 코사인 유사도\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_accuracy_and_similarity(client_file, dictionary_file, original_file_client, original_file_dictionary, n=5):\n",
    "    # 변환된 파일을 읽어옵니다.\n",
    "    client_data = pd.read_csv(client_file)\n",
    "    dictionary_data = pd.read_csv(dictionary_file)\n",
    "    \n",
    "    # 원본 파일을 읽어옵니다.\n",
    "    original_client_data = pd.read_csv(original_file_client)\n",
    "    original_dictionary_data = pd.read_csv(original_file_dictionary)\n",
    "    \n",
    "    # 데이터 포인트 간의 코사인 유사도를 계산합니다.\n",
    "    similarities = cosine_similarity(client_data.values, dictionary_data.values)\n",
    "    \n",
    "    # Top@n 유사도를 찾습니다.\n",
    "    topn_similarities = np.argsort(similarities, axis=1)[:, :-n-1:-1]  # 역순으로 정렬하여 상위 n개를 얻습니다.\n",
    "    topn_values = -np.sort(-similarities, axis=1)[:, :-n-1:-1]  # 역순으로 정렬하여 상위 n개의 값만 얻습니다.\n",
    "    \n",
    "    # 모든 결과를 출력하고 정확도를 계산합니다.\n",
    "    successful_distances = []\n",
    "    unsuccessful_distances = []\n",
    "    successes = 0\n",
    "    success_indices = []  # 성공한 인덱스를 저장할 리스트\n",
    "    for i, (indices, scores) in enumerate(zip(topn_similarities, topn_values)):\n",
    "        \"\"\"print(f\"\\nTop {n} inferences for client {i + 1}:\")\"\"\"\n",
    "        for rank, (idx, score) in enumerate(zip(indices, scores), 1):\n",
    "            \"\"\"print(f\"Server {idx + 1} with similarity score {score}\")\"\"\"\n",
    "            if original_client_data.iloc[i].equals(original_dictionary_data.iloc[idx]):\n",
    "                successes += 1\n",
    "                successful_distances.append(score)\n",
    "                success_indices.append((i + 1, rank))  # 성공한 인덱스를 추가\n",
    "            else:\n",
    "                unsuccessful_distances.append(score)\n",
    "        if successes == 0:\n",
    "            print(\"No successful match found.\")\n",
    "    \n",
    "    # 정확도 계산\n",
    "    accuracy = successes / len(client_data)\n",
    "    \n",
    "    # 성공적으로 일치하는 데이터 포인트와 클라이언트 데이터 포인트, 그리고 일치하지 않는 데이터 포인트와 클라이언트 데이터 포인트 간의 평균 유사도를 계산합니다.\n",
    "    successful_mean_similarity = np.mean(successful_distances)\n",
    "    unsuccessful_mean_similarity = np.mean(unsuccessful_distances)\n",
    "    \n",
    "    # 유사도의 분산 계산\n",
    "    successful_similarity_variance = np.var(successful_distances)\n",
    "    unsuccessful_similarity_variance = np.var(unsuccessful_distances)\n",
    "    \n",
    "    return accuracy, successful_mean_similarity, unsuccessful_mean_similarity, success_indices, successful_similarity_variance, unsuccessful_similarity_variance\n",
    "\n",
    "# 변환된 파일 경로\n",
    "#client_file = \"Client_smashed_data_epoch10.csv\"\n",
    "dictionary_file = \"Dictionary_smashed_data.csv\"\n",
    "\n",
    "# 원본 파일 경로\n",
    "original_file_client = \"random_300.csv\"\n",
    "original_file_dictionary = \"random_500.csv\"\n",
    "\n",
    "# Top n 설정\n",
    "n = 5\n",
    "\n",
    "# 정확도 계산 및 평균 유사도 계산\n",
    "for i in range(1, 11):\n",
    "    client_file = f'Client_smashed_data_epoch{i}.csv'\n",
    "    accuracy, successful_mean_similarity, unsuccessful_mean_similarity, success_indices, successful_similarity_variance, unsuccessful_similarity_variance = calculate_accuracy_and_similarity(client_file, dictionary_file, original_file_client, original_file_dictionary, n)\n",
    "\n",
    "    print(\"\\nAccuracy:\", accuracy)\n",
    "    print(\"Successful Mean Similarity:\", successful_mean_similarity)\n",
    "    print(\"Unsuccessful Mean Similarity:\", unsuccessful_mean_similarity)\n",
    "\n",
    "    # 분산 출력\n",
    "    print(\"Successful Similarity Variance:\", successful_similarity_variance)\n",
    "    print(\"Unsuccessful Similarity Variance:\", unsuccessful_similarity_variance)\n",
    "\n",
    "    # 성공한 인덱스들을 출력합니다.\n",
    "    print(\"Success Indices:\", success_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "98947347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 리그리션 데이터 추출용\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def calculate_accuracy_and_distance(client_file, dictionary_file, original_file_client, original_file_dictionary, n=5):\n",
    "    # 변환된 파일을 읽어옵니다.\n",
    "    client_data = pd.read_csv(client_file)\n",
    "    dictionary_data = pd.read_csv(dictionary_file)\n",
    "    \n",
    "    # 원본 파일을 읽어옵니다.\n",
    "    original_client_data = pd.read_csv(original_file_client)\n",
    "    original_dictionary_data = pd.read_csv(original_file_dictionary)\n",
    "    \n",
    "    # 데이터 포인트 간의 유클리드 거리를 계산합니다.\n",
    "    distances = euclidean_distances(client_data.values, dictionary_data.values)\n",
    "    \n",
    "    # Top@n 유사도를 찾습니다.\n",
    "    topn_similarities = np.argsort(distances, axis=1)[:, :n]\n",
    "    topn_values = np.sort(distances, axis=1)[:, :n]\n",
    "    \n",
    "    # 결과를 저장할 데이터프레임 생성\n",
    "    results_df = pd.DataFrame(columns=[f\"Rank_{i+1}\" for i in range(n)])  # 각 클라이언트의 서버 랭크별 점수를 저장할 데이터프레임\n",
    "\n",
    "    for i, (indices, scores) in enumerate(zip(topn_similarities, topn_values)):\n",
    "        result_row = pd.Series(scores, index=[f\"Rank_{j+1}\" for j in range(n)])  # 클라이언트의 서버 랭크별 점수 저장\n",
    "        results_df = results_df.append(result_row, ignore_index=True)\n",
    "    \n",
    "    # 결과를 CSV 파일로 내보냅니다.\n",
    "    results_df.to_csv(f\"client_scores_{client_file.split('_')[-1]}\", index=False, header=False)  # 첫 번째 행과 열의 이름을 빼고 저장\n",
    "\n",
    "# 변환된 파일 경로\n",
    "dictionary_file = \"Dictionary_smashed_data.csv\"\n",
    "\n",
    "# 원본 파일 경로\n",
    "original_file_client = \"random_500_C.csv\"\n",
    "original_file_dictionary = \"random_500_D.csv\"\n",
    "\n",
    "# Top n 설정\n",
    "n = 5\n",
    "\n",
    "# 정확도 계산 및 평균 거리 계산\n",
    "for i in range(1, 11):\n",
    "    client_file = f'Client_smashed_data_epoch{i}.csv'\n",
    "    calculate_accuracy_and_distance(client_file, dictionary_file, original_file_client, original_file_dictionary, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "09b2f9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 1, 2, 3, 4], dtype='int64')\n",
      "DataFrame Rows: 500\n",
      "Labels Length: 500\n",
      "Logistic Accuracy: 0.68\n",
      "SVM Accuracy: 0.7\n",
      "[[38 16]\n",
      " [16 30]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 로지스틱 리그리션\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CSV 파일 로드\n",
    "df = pd.read_csv(\"client_scores_epoch5.csv\", header=None)\n",
    "print(df.columns)\n",
    "\n",
    "# 열 이름 변경\n",
    "new_columns = [f\"Rank_{i+1}\" for i in range(len(df.columns))]\n",
    "df.columns = new_columns\n",
    "\n",
    "# 데이터와 라벨 분리\n",
    "X = df  # 첫 번째 열은 라벨이 아니므로 제외\n",
    "y = [1] * 250 + [0] * 250  # 라벨 할당\n",
    "print(\"DataFrame Rows:\", len(df))\n",
    "print(\"Labels Length:\", len(y))\n",
    "# 데이터를 학습용과 테스트용으로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 로지스틱 회귀 모델 초기화 및 학습\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "svmreg = SVC()\n",
    "svmreg.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터로 예측 수행\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "svm_pred = svmreg.predict(X_test)\n",
    "\n",
    "# 정확도 출력\n",
    "print(\"Logistic Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# 정확도 계산\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 로지스틱 결과의 confusion matrix 시각화\n",
    "svm_cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(svm_cm*0.01, annot=True, cmap='Blues', fmt='g')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix - Logistic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcf36159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ad5981c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.           0.70214453   1.10814135   1.35915652   1.41457951]\n",
      " [-16.94100368 -13.39400073 -13.19733866 -13.17894935 -13.02198193]\n",
      " [ -5.51157092  -5.16315518  -5.00768012  -4.89222087  -4.76732862]\n",
      " ...\n",
      " [ -6.31313011  -6.01155205  -5.90218768  -5.82402522  -5.81728741]\n",
      " [ -5.94803162  -5.93243583  -5.89034991  -5.78746285  -5.72481807]\n",
      " [-14.81323344 -14.76390425 -14.58024101 -14.51941908 -14.47213104]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAGDCAYAAACBTdwmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAAsTAAALEwEAmpwYAABex0lEQVR4nO29e5glVXX3/13d9CjNgIQzoIShT0+8RVEuYQQReCUCBjFCohIYGhwwP1ubMJD8vETpPHHMa2uiRIMQlSGAA+cEjcYgGu/ECwxCMsNVuSlOd8/AyGWIMDM9wNC93j+qTnedOrXrcupe5/t5nnq6T1137dq197fWXnttUVUQQgghhJD86cs7AYQQQgghxILCjBBCCCGkIFCYEUIIIYQUBAozQgghhJCCQGFGCCGEEFIQKMwIIYQQQgoChRkhJUZEtovI76V4/mERURHZzf79HRFZmcJ1fiEixyV93oBriohcLSL/KyL/ndE1jxWRB7K4VljSeqYe11EReVna1yGk7FCYEWIjIpMickLAPgeJyPdF5EkR+a2IbBCRk+1tx9mNz+ddx9wsIufY/58jIrO2oHIuv+txrftF5N0e6y8UkfUAoKqLVfXXMW47Eqr6FlVdG+ccIvIlEfm467wHqeqPYyUuOscAOBHAUlU9wm9HEbkqSFiIyGoR2SUi2+zlQRG5TET2b+2jqjep6iuTu4X4JPFM4yAiXxSRazzWHyIiz4rIPl2ed7WINOKnkJBsoTAjJBrfBPADAC8BsB+ACwA87di+A8DZIjLsc46f2YLKuTzisd9aAO/yWH+2vY3Eow5gUlV3+O0kIscAeGnIc35FVfcEsA+AP4VVTjY4xRnpYC2At4vIHq71ZwP4lqo+mUOa0LISE5I1FGaEABCRawEMAfimbcH6kMc+SwAsA3CFqj5nL+tU9WbHbr8F8CUAH00gWdcCOEZE6o40vBrAwQCus3/PW3FE5GQRude21jwsIh+w158jIs40uo97q4jcISJPi8gmEVltSpCI/FhE/j/7/7tcVj9tdUeKyFdF5Dci8pSI/FREDrLXjwIYAfAh+5hv2uvnrZUi8gIR+ScRecRe/klEXmBvO05ENovI+0XkMRHZIiLn+qT3d0XkBtvC+SsReY+9/s8B/AuAo+x0fMxw/G4ALgWwynQNL1R1l6r+AsDpAB4H8H5n+h3nnxSRD4rI3SKyQ0SuFJEX292L20TkhyLyO479Xy8it9jW2rvE0f1rP5v/KyLr7GO/b5dZiMgLRaQhIlvtY/9HRF7sOK71TPtE5G9EZMrO32tE5EX2tla39koRmRaRJ0Rk3HH9I0TkZ/b5t9jWwkUh8upnAB4G8A7HufoBnAngGvv3u0XkPrG6nb/neicOEpEf2M/4URG5SEROAnARgNPt53uXva9nebC3rRaRr9n59DSAc+x7Wm+/G4+KyGeC7oeQuFCYEQJAVc8GMA3gbbYF61Meu20F8CsADRH5k1bD5sEEgHeISKwuK1XdDOBHsCwHLc4G8G1VfcLjkCsBvNe22LwGwH+FvNQOWJa5vQG8FcCYiPxJiPQd0rL4Afj/ATwA4HZ783cAvByWVfF2AE37mDX2/5+yj32bx6nHAbwewKEADgFwBIC/cWx/CYAXATgAwJ8D+GeneHHxZQCbAfwugHcC+ISIvElVrwTwPixYL01C+q8A/FRV7/bNDAOqOgvgGwCO9dntHbC6VF8B4G2w8u4iAPvCqqMvAAAROQDAfwL4OCyL3AcA/LuI7Os415kAzoWV74vsfQBgJaw8OxBADda97/RIyzn28ocAfg/AYgCXufY5BsArARwP4G9F5FX2+llY+bUEwFH29vN87tvJNWi3Dp8AYADAt0XkVFj58XZYeXITFj5M9gTwQwDfhfWMXwbgRlX9LoBPwLJgLlbVQ+zzepYHx3VPBfA1WO9CE8AlAC5R1b1gWU3/LeT9ENI1FGaEhEStiWX/EMAkgH8EsMW2Br3ctd9vAHwRwN8ZTvV626rQWh7yuexa2MJMRPpgWZtM3Zi7ALxaRPZS1f9V1dsN+7nv68eqeo+qztkC5DoAbwxzrJ2uY2CJhVNU9Wn7nFep6jZVfRbAagCHtCwvIRgB8Heq+piqPg7gY2gXp7vs7btU9dsAtsMSCu50HQjgaAB/rarPqOqdsKxkXt3DXvd1IID3AvjbkOk28QgsIWXiUlV9VFUfhiU6blPVO1T1GQD/AeAwe7+zYInyb9vP6gcA1gM42XGuq1X1QVXdCUtEHGqv3wVLkL1MVWdVdUPrWbkYAfAZVf21qm4H8BEAZ0h7t97HVHWnqt4F4C5Y4hn2OW9V1edVdRLA5Qhfjq4F8EYRWWr/fheAf1XVXbBE5CdV9T5VfR6W4DrUtpr9MYDfqOo/2s94m6re5nWBkOXhZ6p6vZ2/O+18e5mILFHV7ap6a8j7IaRrKMwIMSCWU3Krm+4iwLJiqer5qvpSWD5KO2B3t7j4BwB/JCKHeGy7VVX3dix+/ktfB7C/iLwewHEABmFZTbx4B6xGekpEfiIiR4W8zyNF5Eci8riIPAWrIVwS8tgDYQmAlar6oL2uX0T+XkQesruEJu3dQ50TljVjyvF7yl7XYqvdQLeYgWXZ8TrPk6q6zXWuA0Km459gCcCn3BtEZMRRNr4TcJ4DAPj5ST3q+H+nx+/WvdUBnOYU9bCsV07/td84/nfmy7UAvgfgy2J1D39KRAY80uKV97sBcFqHPa8hIq8QkW+J1YX9NCwBFeqZq+o0gJ8COEtEFgP4Eyy8V3UAlzju+UkAAitfDwTg92Hjvreg8rDJdcyfw7Jk3m93//5xyGsR0jUUZoQsoG0/VN/ncM7/RMfOqpsA/DOsbkP3tq2wGvb/GytBqjOwulbeBctq9GVVfc6w7/+o6qmwurGux0K3yw5Ygg4AICIvcR36rwBuAHCgqr4IlrVPgtImIrvb1/knVXWKkzNhdQmdAKv7bLh1SCupAad+BFZj3GLIXheVRwDsY3d3Oc/1cMjjjwfwaVtotMTIz0TkTFVtOsrGW0wnsK2cb4NlCYvLJgDXukT9Hqr690EH2tbFj6nqqwG8AZalycty6JX3z6NdLJr4AoD7Abzc7vq7CCHKkYOWdfgdADaq6gZ7/SZYXfTO+95dVW+xt5nCxbjLWZjy4K4DfqmqK2C9U/8A4GvSOUiBkEShMCNkgUdhruQhIr8jIh8TkZeJ5SS9BMC7AZi6Nz4DqxF8lWF7WNbCciJ/BwzdmCKyyLbivMju/nkawJy9+S4AB4nIoSLyQlhdi072hGVJeEZEjoAlrMJwFYD7Pfzx9gTwLCyfvEFYlhMnvvkMqyv1b0RkXzuP/xZA5LAHtnC+BcAnxXJ+PxiWBSTsuV4Bq5vuUCx0Cb4NVveiLyKym+17dR0sn7gknMYbAN4mIn9kWyVfKNZggqVBB4rIH4rIa8Vyqn8aVhfdnMeu1wH4KxFZZluuWn5az3vs62ZP+9zbReT3AYyFvTGbf4cllD6G9nL+RQAfkYUBJC8SkdPsbd+CZVH+S7EGjewpIkfa2x4FMGyL467Kg4icJSL7quocrIE9gHe+EZIYFGaELPBJWILgt2KPaHTxHCzrzw9hNUA/hyVAzvE6me3D8yl0+he1RgI6l9f5pOunAJ4CsFlV/8dnv7MBTNrdSO+D5S8Eu4vx7+x0/xLAza7jzgPwdyKyDZYICuvgfAaAP3Xdx7GwuqCmYFki7kWncL0Sli/cb0Xkeo/zfhyW79TdAO6BNXjg4x77hWEFrGf2CCxB9VFV/WGYA20ft9+0Fnv1E7bvkYnTRWQ7rOd1Ayxxerh6h0OJhC0sWo7wj8OyFn0Q4erxl8CyvD4N4D4AP4HVvenmKnv9TwFsBPAMwo9I/QAsUb8NwBUAvhLyOACAWmFL/h3AUtiDRez1/wHLWvVlu2z/HMBb7G3bYA2ceBusLtZfwvIDBYCv2n+3ikjL3zJqeTgJwC/sZ3oJgDMCnj8hsRHVoF4FQgghhBCSBbSYEUIIIYQUBAozQgghhJCCQGFGCCGEEFIQKMwIIYQQQgoChRkhhBBCSEHYLXiX4rNkyRIdHh7OOxmEEEIIIYFs2LDhCVXd12tbrsJMRK6CFYH6MVV9jb1uH1jxb4ZhTeXyZ6r6v37nGR4exvr169NNLCGEEEJIAojIlGlb3l2ZX4IVwM/JhwHcqKovB3Cj/ZsQQgghpPLkKsxU9afonNz3VCxMx7EW1mS2hBBCCCGVJ2+LmRcvVtUt9v+/AfBir51EZFRE1ovI+scffzy71BFCCCGEpEShnf9VVUXEc84oVV0DYA0ALF++nPNKEUIIIRHZtWsXNm/ejGeeeSbvpFSSF77whVi6dCkGBgZCH1NEYfaoiOyvqltEZH8Aj+WdIEIIIaSKbN68GXvuuSeGh4chInknp1KoKrZu3YrNmzdj2bJloY8rYlfmDQBW2v+vBPCNHNNCCCGEVJZnnnkGtVqNoiwFRAS1Wi2yNTJXYSYi1wH4GYBXishmEflzAH8P4EQR+SWAE+zfhBBCCEkBirL06CZvc+3KVNUVhk3HZ5oQQgghhOTC4sWLsX379ljnWL16NRYvXowPfOADkY/90pe+hPXr1+Oyyy6LlYakKGJXJiGEEEJIT0JhRgghVafZBIaHgb4+62+zmXeKSFnJqCw99NBDOOmkk3D44Yfj2GOPxf333w8A+OY3v4kjjzwShx12GE444QQ8+uijHcdeccUVeMtb3oKdO3ei0WjgiCOOwKGHHor3vve9mJ2dBQBcffXVeMUrXoEjjjgC69atS+UeuoXCjBBCqkyzCYyOAlNTgKr1d3SU4oxEJ8OyNDo6iksvvRQbNmzAxRdfjPPOOw8AcMwxx+DWW2/FHXfcgTPOOAOf+tSn2o677LLL8K1vfQvXX389Jicn8ZWvfAXr1q3DnXfeif7+fjSbTWzZsgUf/ehHsW7dOtx888249957E09/HIoYLoMQQkhSjI8DMzPt62ZmrPUjI/mkiZSTjMrS9u3bccstt+C0006bX/fss88CsMJ7nH766diyZQuee+65tjAU11xzDQ488EBcf/31GBgYwI033ogNGzbgda97HQBg586d2G+//XDbbbfhuOOOw777WnOIn3766XjwwQcTS39caDEjhJAqMz1tXM8eThIJn7KUJHNzc9h7771x5513zi/33XcfAGDVqlU4//zzcc899+Dyyy9vC0Xx2te+FpOTk9i8eTMAK47YypUr58/xwAMPYPXq1YmmNQ0ozAghpMoMDXmubu5zfkev1FlnAUuWUKARA4ayZFzfJXvttReWLVuGr371qwAsgXXXXXcBAJ566ikccMABAIC1a9e2HXfYYYfh8ssvxymnnIJHHnkExx9/PL72ta/hscesOPVPPvkkpqamcOSRR+InP/kJtm7dil27ds1fpyhQmBFCSJWZmAAGB9vXDQ5iHJ/o6JUCgK1b6YJGDBjKEiYmYp12ZmYGS5cunV8+85nPoNls4sorr8QhhxyCgw46CN/4hhVrfvXq1TjttNNw+OGHY8mSJR3nOuaYY3DxxRfjrW99K/bbbz98/OMfx5vf/GYcfPDBOPHEE7Flyxbsv//+WL16NY466igcffTReNWrXhUr/UkjquWfZnL58uW6fv36vJNBCCHFpNm0/ICmpy3rxsQE+s4egV/1X68Dk5OpXZ7ubQXhvvvuiyZM+DAj45XHIrJBVZd77U/nf0IIqTojIx2N59C41X1pIim3odZAvpZ1rjWQr5UsUjI8yhJJFnZlEkJIhTE5+Hv1SjlJym3IbyAfIaQTWswIIaSihLFWXXih5VfmJAG3oXkyGshHSGWgxYwQQipKkLVqZAR44gmg0bB8ykSsv2vWJNdbldFAPkIqA4UZIYRUlLDWqpERy9F/bs76m6QLUUoD+QipLBRmhBBSUfysUkuWtPudpRVsdmTEssClZZEjpGpQmBFCSEUxOfirWn5lrcCy7343cO656U2BmKZFjpQfEcH73//++d8XX3xxYIT+66+/3jjH5erVq3HxxRd3lZY4x37pS1/C+eef39WxTijMCCGkorSsVf39/vs99xywa1f7uiKMnOSUUb3BC17wAnz961/HE088EfoYP2FWdijMCCGkwoyMWJaqbshz5GRrRGlaVjzSHWmI5d122w2jo6P47Gc/27FtcnISb3rTm3DwwQfj+OOPx/T0NG655RbccMMN+OAHP4hDDz0UDz30kPHcDz30EE466SQcfvjhOPbYY3H//fcDAL75zW/iyCOPxGGHHYYTTjgBjz76aMexV1xxBd7ylrdg586daDQaOOKII3DooYfive99L2ZnZwEAV199NV7xilfgiCOOwLp16+JnBijMCCGk8nQ7AnKob3Nu5irGPyseaYrlv/iLv0Cz2cRTTz3Vtn7VqlVYuXIl7r77boyMjOCCCy7AG97wBpxyyin49Kc/jTvvvBMvfelLjecdHR3FpZdeig0bNuDiiy/GeeedB8CauunWW2/FHXfcgTPOOAOf+tSn2o677LLL8K1vfQvXX389Jicn8ZWvfAXr1q3DnXfeif7+fjSbTWzZsgUf/ehHsW7dOtx8882JWfAYx4wQQirOxER7PDM3ixZZDa2zO3MQOzAx+yEAGj9cfxfT+DD+WfHwE8tx/Qb32msvvOtd78LnPvc57L777vPrf/azn+HrX/86AODss8/Ghz70odDn3L59O2655Racdtpp8+ueffZZAMDmzZtx+umnY8uWLXjuueewbNmy+X2uueYaHHjggbj++usxMDCAG2+8ERs2bMDrXvc6AMDOnTux33774bbbbsNxxx2HfffdFwBw+umn48EHH+w+E2xoMSOEkIrjHhlZq1lLa5TkVVcBV1/tGDnZvxlr8B6M4LqFk3RrrrLNLM2pN2BYf42+qV9j+Oxj0TzvZt/DGP+seKQtlv/yL/8SV155JXbs2JHI+ebm5rD33nvjzjvvnF/uu+8+AJYl7vzzz8c999yDyy+/HM8888z8ca997WsxOTmJzZs3AwBUFStXrpw/xwMPPBA4OCEOFGaEENIDOEdGPvGEtThHSbaNnJwbahdlLbppgcfH0Zw5FaO4AlMYhqIPUzqEd3/hiI6QHU4Y/6x4pC2W99lnH/zZn/0Zrrzyyvl1b3jDG/DlL38ZANBsNnHssccCAPbcc09s27bN93x77bUXli1bhq9+9asALIF11113AQCeeuopHHDAAQCAtWvXth132GGH4fLLL8cpp5yCRx55BMcffzy+9rWv4bHHHgMAPPnkk5iamsKRRx6Jn/zkJ9i6dSt27do1f524UJgRQghpJ8kWeHoa4/gEZrBH2+rnsKgtZIfbV6mb+GccxZkuWYjl97///W2jMy+99FJcffXVOPjgg3HttdfikksuAQCcccYZ+PSnP43DDjvM1/m/2WziyiuvxCGHHIKDDjoI3/jGNwBYYTFOO+00HH744ViyZEnHcccccwwuvvhivPWtb8V+++2Hj3/843jzm9+Mgw8+GCeeeCK2bNmC/fffH6tXr8ZRRx2Fo48+Gq961asSyQNR1UROlCfLly/X9evX550MQgipBu5JNgGrBe4mMuzwMPqmfg0NYQeo1y2rXTckmeRe4r777oskKLpwF+x5vPJYRDao6nKv/WkxI4QQ0k6S4fonJjAkm0PtGsdXyc8xnZa05GCw4PShMCOEkIoSS5B4tcDdnHBkBBPvm8agGIaEOojjq2QSda1uUq8QDxRspIhQmBFCSAUJijkVWZSECGJlOufI54/BmmsHF0aFLn4GA3i27fRxfZVMoq6/39uSduGFDGBLigmFGSGEVJCgrr3IoiQg4mvQOecNcNc28cRcDVfjXNQxCcEc6jKNNStvjtUtZnJMtwO0d7B1KwPYtqiCr3lR6SZv6fxPCCEVpK/PEkhuRCzr0tRU5zZf53u/E87NYXg45DlD7xgdL8f08XHvy5mwb6dn2LhxI/bcc0/UajWISN7JqRSqiq1bt2Lbtm1tAWwBf+d/CjNCCKkgJv1Tq1nWIi98RUmAoArQbQuE3jEZmk3g3HM7J2k3kYA+LBW7du3C5s2b2wKskuR44QtfiKVLl2JgYKBtvZ8w45RMhBBSQbymYVq0CHj6afMxvs73Xid0OIaZrHAd5wy9YzKMjFj+ZF5iVKRdI/ZiANuBgYEOaw7JF/qYEUJIBfGKeLHnnmbLUaAoCQihETr4aA4h/Z980nu9U5TVaoaIIBy6STKGwowQQiqKO+KFSaAAwO67A2efHaA9fIJYdei22nas2f0CjJztHqK5sGMTZ2K4fxP6ZrZjeHwkNc0Txhi3c6fHyq5GSRASDwozQghJgSIaWkwCRQS+0yOFxTnycnLnizGy9VLjEM3mxCRGB5uYml0KhaSqebyMdG5mZoCzznI9q4CRqISkAZ3/CSEkYYo6PZBXutx+Vi1iOcGHGHmZ4uBMT5wjNoOavflndXa2AxVI78ApmQghJANaVrKzziqmocXLTcwkUqan1LoZEWC33ay/Qaa/VgaY4lM4wvObIvXHmZbJD2cvbL3uv+/MDLByJdCnz2MYG9HEivYdXKbHIlpHSXmhMCOEkLg0m2guuQCjZ+3wjZmVluiIgttNzCRShmTTgsBqRWn16290+mOZcAgaU7dqSoMz2wjTtTk7Cyj6MIVhjOKKBXHmGqiQ+AwLhKhq6ZfDDz9cCSEkFxoN1cFBrWOjWk2zeanX805sJ3by29I5KDu0gRXRbqRe97/5wUHrYn7Xbd8l9fsOSnLbLWOjdYArgaZztHZ136NI+3bSmwBYrwZNk7uoSmKhMCOE5IbdMgtmo+iSQtESKSK2YMCZ/ipFpPMkLcXhp1KCrptD/niJJ9Mte6XXdNutfcpaJki6+AkzOv8TQkgMmjKCcUxgCnUA3lPa1OtW71eejv8AvOcs8kqUn58Y4O2hn7U3f4I4s6Wvz3t+zVrNCqnhHtCx++7mmRTCUILsISlA539CCEmBZhMYlSswhWF4ibLBQaDR6Aj5lQ9RYnL5OWGZgsEaAsc2T24U3sfK6Xe3dq13/FvAe0CHc3s3FMHvkBQLCjNCCOmS8XFgRr1aZbUCrOYcHqONKDG5nMM3AaC/3/pbr1vDFcfHO5WWx5DP5srvYXTtMbnGZ43qfG+a4MAUnPfJJ9uzKipZDHYg5YJdmYQQ0iXG+bihmFPvbs3cSGLy8IgB2vLu3UwynlyYezFlcQuvuTnXrLH+D9PDTKoDuzIJISQFjCEf6gUTZUAy8SkiRsLPOlaZmyQD94eZ4tOUla14cdde22mJAzjrE2mHwowQQrokh/m4jQR22SWR2IhKK89YZUCywjBgDncA/llsGnfBWZ9IB6bhmmVaGC6DEJIXRQ354BmKwRm8q7/fN5SFJ35Bu+KkKyUiJrd7HIWgUVul9do2qzzUtmmjtkobOFMHZYdnPviF2yDVBYxjRggh1cUkQGo1j53jqKUujs1TuGYiDE0XGRubX28KPlyvZygeSaHwE2bsyiSEkDLh0Wdp6prbutWjSzNO35lXf55plKbjEOcUUFk6tYfpfoyNKT/XrJlfPw3vvtvp6WJ1h5NiQGFGCCEOCj23oSEW2dA+242HdOgtDxXXxAoMT/043D07ldbEhBX4q8Ce66kLQ5MqdkSpHYLZB28ETazZ/QLUMQnBXPHCrJDMoTAjhBCbKDFYfU+SlrIzWGcmcJHxkA7d4PK8b2IFRmEFyY18z/RcN49kaMV+AzCBizCIHW2bBweBiZNvBkZHMbL1UkxiGebQj8mdL8YImsX+QCDpYurjLNNCHzNCSBLE9vdJ26lJRBtYoXVsVMGs1rHRmmxcRGu1kGl3pdHP/ylMevw814swMKJFamkJ4WOmgPXcZEoFcwvXNxS4Rm1VroMmSPqAzv+EEBJM6BFyplbeo6FtYIXW+zclIggatVU6iO3tDTa2WyP/omhCR/pNk6+HGhXoo2RzGZFpeC6pp8VUHoLUoKHAxRLLpBRQmBFCSAhCWcz8WnlXQ9vAik4hFUMQ1GvbvNNX2zaftKhWIeM9Y2PwSVx54bQKtaJxZCYufJ5LYUc+GhIWSyyTUkBhRgghIQhlWfFr5V3bkrZ8pBHzyvOesd3qIg2jJG016BWrK01x0SFCa6uMzyXJfOuqS9R1UGPsJusn5rQuUwt5bee3UYDXo6eXFBMKM0IICUlgw+vXyrtUTtKWj7QsP/P37PRbi3gBU9rSEBeBYtKV2UnlW1ddoh5WxQ4rquzQBs6cL3B5B+Yl6UNhRgghSREUzdWh7Or9mxIVJ6k32DFMS6ZD00irb/erR2YnlW9dCbyQVtTWecK6p5FyQ2FGCCFJ0WioLlrU2aoODHS0nmkIqcbYTdZgAsxqvX+TNsZuinlDDmKYlkyH9vcnLy6M+hGzxsz2EzphRVBXutV1kMmK6lU+KM6qC4UZIYTEoKOB3OM9oQVMoo1r2iazGOfPsvvNqB9r2yJndpR0p20xc1vO2J1ZXSjMCCGkS6L6M6VKFsMLYyjJrCw8sUSLK5FRHO3T8jHzKkaFHUlKEsFPmIm1vdwsX75c169fn3cyCCEVZHjYiobvpo5JTGKZa2XdmvcnLfr6rPbZjYg151AP0WxaEwxMT1vB9ycmQkxj1JrawTFbQR9m4TVttClLu76u46DmyQ2Mf/sYz3IFWMVoepqPusqIyAZVXe61jVMyEUKID6apEDsmpg4x83TsaXZM0/+Y1leYsHNgtuX5yjeiOXNq23a/eSzjXNfvoJHPH4PJSaDRME9gzkfdu1CYEUKID8YGsjZjmTZErL8BM08nMg/nxIS5Ja8yXSrajjyfXYpRXIEmVszvY5zHMoMsHRmxio1XMerVR01AHzNCCPEj11ALpgT10lC9Lh9Ao6Hm2QdcYTUatVWFzNJee9S9BMroYyYikwC2AZgF8Lwa+mIB+pgRQtKlK78iF3QP6xKjk5/Zn8/DlawNwRzm0G/9GBwMtHYWkSTKJMmPMvuY/aGqHuonygghJG3C+BUF9bb1hM9QbCc6D4xOfob1sASLSZQBwFD/I6G7oLMiStYl0i1OCkvRhRkhhBSeMA1l5X2G0lILXShaH81m5fnapZ4qO0ldmYTQOu8873N4Cc+ZGWs9qQCmPs68FwAbAdwOYAOAUY/towDWA1g/NDSUaN8vIYS48fP38Z0iyLFz6xzAgv9TZXyHDJkQ23+rCx8zv1kITIclGdA1zLmc5cnkC+eeaaB1jjQmsyfZgjIGmAVwgP13PwB3Afg/pn3p/E8ISZOghjZwiiDX1ECVjOjukQmeE3Z3c68RveC7yeOw4joMQQM9vNIXdqnXGXy2CvgJs8I6/zsRkdUAtqvqxV7b6fxPCEmTIP/zUEFo7Z278GUvBx43NoyNmMJwx65Z3GtU53jj4IzWQIEIgwSCBnqYykAYRIBrr+0c3FDSMQw9S+mc/0VkDxHZs/U/gDcD+Hm+qSKElJEk/IaC/M89/cewAxO4qGPnLnzZy4FHJnQE4W2tz+BeowaCNbqytQLQRnDiCnKLC3P/IuZz+MU/I+WnkMIMwIsB3CwidwH4bwD/qarfzTlNhJCSkZQ/elBD29ZQYg51TGIN3oMRXNexc9C5TEIyjQGPbcS9gIdaGKp5D40s4kjUKOK6q3M5BnqY7r+/f0Fove99/ufoagYCUg5MfZxlWuhjRkg1SDqgZlK+OJF8lgJ29tts2jY2lrJfWkqOb2Xzp5svf5jVOjZ2TlQfoeD4leWw+cIAs9UFZXT+j7JQmBFSfjwbq0W7tFFb1XXLlOTotUiNZMDOps1+owlTdfZO0Zu8lOIiA0WZdL6YzlfK/O8BKMwIIYXHd1Rcl41j2UavmYSkaUksPEJV4i8kqUI8zlVUkZObpZV0jZ8wK6qPGSGkxzA6xTsdyGdm0LzwttCuUKGDuqbuwBUOP9+jKPsnduECOYMFPqKkA9y6nLiaGClstH1TwNk1axiItpSYFFuZFlrMCCk/YSxm3cTFCrRyFMgRKlXLRxJOTzkRKnkhzaPdWr2KbH2NamkFCvNoexawK5MQUnQ8G19sb3PArmNj8o1jwVrcVHyFooaiL1I/nYZ8RCG6Y+Poz7R7e+Nkf1TfxILp7p6EwowQUgraGqfaNm0MnNPWmghmjQ1N15oihRa3cBqnYOLTD6+8C/WIQtxjnGxIMwvjGiyjWFoL/vh7BgozQkg5cbXS9do2YwPdtTUgZovrFhKFdLguiXO/SWDUaiEeUQh1Eycb0uztTUL0+VlaTcKsYI+/p6AwI4RUAq/G0dTYOhs1XwtWjBa32/RkTrctf8amP1Mya7WQjyggvXEFUFrZkbZuLpHBtGegMCOElBpng1irWUurcQyyBoTSXRFaXOeufj48hbJOdCM+cxgQ4CdQIosiQ7iLwlkzNZxwiiMKi3rfvQyFGSGklDQa3t1YzkYlqFFL0lrg1cCFXTKxTgSNvIzSsudgZknskj5KpHD+fxosnJIQVkW8716GwowQUjqCRFCtttCQ+/mYJdlN5Gehc5+7LT2yQxtjNyWZPZ0kbRbJwS8tsVsoYd+dn3BK+nYo0vKHwowQUjrCiiC3GEqqUYsyOtAtJMaOv0/rMtU+52LafUdRbzSodc5J3CQiGkoy2CEsSU8txm7N/KEwI4SUA0er7Bcaw7R4aYYk3atMowP7+11Cwk9VRvBhiyRMorTeYeOaRcy4wlhiSmgx8yPJQQupz7tKQkFhRggpPi4hYAomG2Q1M506Cfeq0KMDg0xrBoETy5oRpfUOu2/EQRGFscQUKjHx6fbjwtTVXyFjYmmhMCOEFB+XWPCafqkljkLFtYpB7NGBYfphPRIbyzISpfVOoauvcEaqwpjvkiHK7XQzSIUWs2yhMCOEFB8PsdDACq1jo2fQzCTiWpmILTLCtIweIii2Xgp7vymoqIq5dZWaqP6ZJTYmlhYKM0JI8YkoFgI1SAQLkvtciU4abmoNa7W4WdA9KXT1pZ72ilnA0iRM12WHXyTJFAozQkjxSTpYU0gvZ9Nlx8YS0gGmflcPYZapa1TCQifVtBtO3hi7iVrNgyCLGS1k+UNhRggpBxHFQtvuHpOeh+lbS93SE7GPr8yGodTS7vGQGlihg7KDgsMDLx1rCidD8sFPmIm1vdwsX75c169fn3cyCCEp0mwC4+PA9DQwNAScfDKwdi0wM7OwzyB2YA3egxFcZz5RvQ5MTs7/7Ouzmi43IsDcXALpnZrDEKYxgYva0+VKB/HB4yENYyOmMNyxK7PVwv2+TEwAIyN5p4q0EJENqrrca1tf1okhhJCoNJvA6CgwNWW1z1NTwBe/2C7KAGAGe2AcnzCfaHDQaqEcDA1572paHzm96MMUhjGKK9DECmM6iA8eD2Ma3g9oejrtxJSDkRFLoM7NWX9boqzZBIaHLa07PGz99iXyASQuFGaEkNwJqvvHxztFmMnY39Fg9/db5q96HVizpsNsMDFh6SQncXWTV3rnRaMhHcQHj4c0JJs9d40jqKuO1wfO6KiP1op8AEkEUx9nmRb6mBFSXsI4jYcZZTbvG4aNkZ2OkvaNqmToiEZDG7VVVvgSzFo+fVn6KrkeUmPspirFkM2EyP6UhQtOVx1A539CSFEJU/eb9umYLHzRLm3UVuXuOZ91e5b6gIFGQxsD53QE/B1ctCtXIVTmgRJhyP2DoZJfGMWAwowQUlj8rGGtxihqSIu8G+wsw154Xkt2aANnJnfz9bpxiiwaT9IhjTJEi1lxoDAjhBSWsDGXwoqtokyTmJU4NLadrS7dJG7eZ1J5Gk/SIQ1N5PtueBVYxwHzs3Dk0Y1dQfyEGcNlEEJypeVf7HaWdxIlBMLwsOWjHOccZcIY7gNzmEO/9aNWAxYv7j52wvAwhqd+zPAUGZJ6GJdpYJ99rHVPblUMySZM6IcXQroMDlqDVAA0L7wNo1s/iRnsMX+e1maOYekOv3AZFGaEkNxpNRZeggqI1hil1aAVFaMQxSQmscz7oKitarOJ5rk/xOiuy9ob50XPY81Vu7FxToG0PzC8Pog64gDaF+u1j50sYBwzQkihacVcqte9t0cJgZBGXLIw5BXuyTPcB3ZgAheZD5qZsZRwWEZGMHL1CVhT+wjqmIRgDvXa9sxFWS+F1EojjIsT35AuAJpYgeGpH6Ovz/zBxJhxKWHq4yzTQh8zQqpBUtNlZu1jFuqaKTqdNcZu0nr/Jsv/Bxu1gRX+jntFdQ7zyaOi+A5mSZp+isYBl5i1prtyjcDlGIBkAZ3/CSFlIYnGyPMcKbZygY7aaaqKoIkRTZOoF61VDcgjDhBMFr9BI6YRuL0kitOGwowQUjhi66QoJ0jZ3BIY7ilNVRF07rKYmgLugyG1ksUvzIppBG4rv6sYMy5rKMwIIYUitlaIeoKUzS2Bp09TVYQ5d96B3cIQcB+0mCVHqzgAqv39C/nYKhbM6/TxE2Z0/ieEZI6n43EUf/SoJzB5KSfkvRzoqJ3miIQw5zbNaF0kAu4jrDN8Lw0Q6Abn9JcAMDu7kI+tYpH2wAMSgEmxlWmhxYz0MiZjSJGNJLENSGFP4DQNpGwC8M3vrH3MithVGUSI+wgq01XJijQxWsNq2zrmIi1q/VEFwK5MQqqJ31RFRW6gYneVhDmBV+bkmSFpKuUiq/AoxLwPdsEF4zcas7AVRgWhMCOkopgaopbfSFEbqEx8zIIsZWx0SkmHdhu7aX6FcdoozPKZ2wRO4VXECqOC+AkzXx8zEfl9ETleRBa71p+UYu8qISQkJhep2dlw++fljzMyYgWer9etiPz1esTpXcKcwJQ5IsX1syK+OP2jVK2/o184DM2pNwCqGIL3Mx/CtL3zaPGczjJ+CSMFJLbfIfrtZYxJsQG4AMADAK4HMAngVMe2203H5bHQYkZ6lTgWs7TdnnLvWWO/VuUIsvZ4BUYdxPb2gLtFev45OcV1vJ+1VcaKpIEzdVB2sJczYdBNVyaAewAstv8fBrAewIX27ztMx+WxUJiRXsUvtqjblyRsT1/cdssvPlKmoxPoCV45wvhHNbBC69hongUh6cBnccpxUT4efPwxTcFma7UCfHyVmG6F2S9cvxcD+C6AzwC403RcHguFGellnAMP3Q2XMwC8u+IUzHk3cjHbrUAfli5GJ3Td9hXCdEeSIrR/VL2ejeiJK/4dL2yHoMy6qDrfFYfJ3S/YLL95uqdbYfZfAA51rdsNwDUAZk3H5bFQmBESsR1qNLQuU6m0W6FGfUUYnUDDF2nhWRbcXZWtwpFFwYkr/uzjPbtgB9sHNmT6YeF4icNMz5SXoa/MdCvMlgJ4iWHb0abj8liqIMz4YU/i4iuI3IWqXvduDGRH7LIXadRXCHNdUXp7CkUPVxh+ozI78iLtfIobkG9sTFXEKH7qMpXPF4njpQs7oXmU2yZdCrMyLUUUZgWaxo/0CKG6EFuFym5QOv1xzoydjlBWjZAWs0aDjUAHrDCKI0zjfDU4nqNvmI88vkhcZayBFbaF3dv9gR9L0aEwy5iCTeNHeoRQgqhVqFIqdJ1z8M1pXaY6u5ocPmZt4rC2rW1sgF98WHek8p4RJr1eYRRJmMZJi+M5Gi1mXlbmrL5IPMSvX2jAXvs2iAuFWcZErTfTnN+Y9BbzdWnQiLQUGjfjKU1dTY2GNmqrvH1rAmZSGly0SxsD5/Rmy5BXhRHWSpWWNSvD6bW6SlfU+3U5/nu6Fbjf35wFuOljqVbrjVcvSSjMMiZMvWkYAFOU94+UnbBTFiXYgHZjyPHrfvUbDWaMu9QLL00eFrOwQj4ta1aQ+bSMX7Ku59hmOa7bHzRFsQw6KEovctmJJcwAvB3ALwE8BeBpANsAPB10XJZL0YRZUL0Zpo4pwPtHykxQA5lC7dqNIcdvwIKxe6fe5cWqQh5deWHFYFqi0c9SVlZRHuY5UgVVlrjC7FcAXhW0X55L0YRZ0PsWVMfQLEwSwVSpp9SwJ20xM4YQaHR5sSqRdYMdVginJZhN5y37lyyFV88SV5itC9on76VowkzV/30LqmN6pW0hOZGi438kHzPTMY4BC/PdO+5D7TADlWicy0CYboA0/b+Czh3GEkwR1I4hP/y+55h9yRFXmF0C4CsAVtjdmm8H8Pag47JciijM/AiymPVCbwzJkYhWjaihXzpiTAVY5wIHLLgbdS81J2KJtaJS9lbNz8oa5JuRlo+ZV7dflDT2spA35Edj7CbPbAqaqKPsxTsP4gqzqz2Wq4KOy3IpmzALDANQzzuFpGq0VZz9m0KP9ordnkWxzoW9WNm6MasiCkytb1hrVlrXb+FXLspWZtLGkB/1/k2e2WQcoIaN1sjqRbtKX7yzhqMyC0ijYfmSeRktvOozfpGQbgkV38xQk8Zuz6L6HIUp6GVz/K+6KCjK8/BLRzdprHKla8iPsPNizmdf0CAdYiSuxWwpgP8A8Ji9/DuApUHHZbmkLsxSeEGdLhmtrxGTy0xVPrhJsoQtlkZd0L8p8GC/9izU9dMQJWUTOkkKlyKKhaI8jyQtZlWvdBO0mBlnLSjod1JRiCvMfgDgXHsC890AnAPgB0HHZbmkKsy6fEGDfFC9XGSSqlNI9YkS6DGOLjCVvVot5GuRRgNXtkYzqRe4qPddlHQl6WNW9Uo3CR8z2+pOi1l3xBVmd4ZZl+eSqjDr4gWNGy7D3XgWpaeAFAe/MuRub+K0Maay7NUNbzxnGlaeIlqOTCQlXIosForyPJIaldkLlW63ozJdg3R8w9oQI3GF2Y0AzgLQby9nAbgx6Lgsl1SFWRcvaFD9GRQuw7mYTMiA1TiS3iSoDPX3L1SsQSOqgvCqqLtqt4rSeOdBEvfeC2KhKBRZBOeJwTm6MXCO1mvbevLV7pa4wqwO4AYAj9s+ZtcDGAo6LsulaBazoPrTdMoogg1QXbSIL0CViNJ2myxWJgva2Fiymijya1GU7q4yQ7GQHSyvnUTxnyCBcFRmHLp4QYPqT9MpnY2nn6WMdXL1iFLMGg3VgYFoIj7pcuKbXi+FSVERDa88pFjIll628HrBdzhRuhJmAD5k/70UwOfci+m4PJaijcoMU38GnTKs9Yy9GNUgSp0XxUcx0XLiKrSNsZs6y7Cp8LMAhyfIib1XxUJZ7r0s6YyKR6NknJmDBNKtMHub/Xel12I6Lo8llzhmAS9f3HczbOPLj5Vq4CfE3WXIb1/jsPZ6zASGtdaYCm5qCasgtEx0UhZrYZW7+1zlkk7/8UisKxNAH4C9ohyTxZK5MMugkjC933wJqkkYId563n7tdmpF03DRRm1V+wcIzvS/ARZgVQ34cKOTfycFFKuezzDKcOmy4apcGCYjHnGd//8VwF4A9gBwL4DNAD4YdFzcBcBJAB4A8CsAH/bbN3NhllEl4X7xnT5otZq10IRcDRoNazBHGAtpkPhaGNY+p3VMWsPa+/vjzSVp6Mbo+GKWHebpnqraxRORQPFcQBGSOwUTq8Zn6PdhUoVn6HiHGVg2HonEMQMwAuAfAQwAuDvouDiLHZbjIQC/B2ARgLsAvNq0f+bCLKVKImy7VRarPglPWIf+VhFrjN2k9f5NVkyh/k06dvx97WXn+Cu9T9CtOPMQC8YvZpli4fQhUHfxBe+kYGLVmJz+TeFe4DJhaJgK9khKR1xh9gtbjH0VwBvtdXcFHRdnAXAUgO85fn8EwEdM+5fRYuZlDQtbF/OFqB6RfApdDben5co9F2Zr6e/vLoEeYsH4xYxZmnN9CPVdR+tiOwUTq8ZniDl/H5SyVdI++e65adEubdRWsdyGIK4wuwDAwwC+DUDsuGY3BR0XZwHwTgD/4vh9NoDLXPuMAlgPYP3Q0FBaeedNzErC63C/KZncFMyqTxIgzCjc+SLmUnFGyxU2ep+oW1xioV7bZr6u432gxmjH+GFV29a5MzNvgSTyIqH89P04NgRhLaXVM8AK0JadtW3aGDin/PecEYnHMQOwWzfHRTh/oDBzLkUclelHlHAHXmKLFrPq4TeYsaOIuVScr+XK64QJ4fl94rTU1etFM3QUgkbDsix05NvAOZ0xdZh5yZFgfoY6VRVEdRQrABumSMS1mL0AwJkALgLwt60l6Lg4S+G6MqO+YAH7R4nw71WmWV9Xj0jPNI7FLM4AAEO669jYMX9eq/JmXe1No7bKO9+cGcPMS5aE87Ojmh+7qfxCzE2UL0Z25UQirjD7LoCvAPgQgPe3lqDj4iwAdgPwawDLHM7/B5n2L1Tk/xD7m8q62/IRdJmq1QG9TuhnGsbHbNAeANCKHxZ3VKYfPg0e62oDYTKGmZcsaeZnVb+Wo8Rt4odEJOIKs58H7ZPGAuBkAA/aozPH/fbNZa5Mzz4mn/0dhdPUBTSGSxe+omvbSv9OkxRpNNqsLrU9dubnb+/TKLGuNhAmY5h5yZJmflb5WTm/GP0CRVdVnKZEXGG2BsBrg/bLc0lVmEXyyvbZ3/VVthBryqMLyOOFpoWsunTzbAtXBxpuonDpLAphMoaZlyxp5mevWDeD7pMNVWjiCrN7ATxnB3u9G8A9accxi7rkYjEzfRlF/XIK8UKzfq4u3T7bMn2gs642ECZjHPs0aqu0XtvGfIxD0oXRrwuvqC9kHMpU8RScuMKs7rUEHZflkrmPWdAXQ5SWNkRB9w1myNq51HRbz/XKBzqx4MdZAQlqG6r4gFgQE8NPmPUhAFWdAnAggDfZ/88AwcdVhpERYM0aoF4HRID+fu/9hoa896/Xrd8jI97HTUwAg4Pt6wYHrfU209Peh07P/i4wOgo0mxFvihQF47N1rG82geFhoK/P+ttsLhQ3N6b1pNyMjwMzM+3rZmas9SQnvB5Ki6B6v6z4tG9e9RTpEpNiay0APgrgmwAetH//LoB1QcdluWQaxyyNL4axMd/Rc0arSiscAs3IpSKsL21rX6/iFmWmiDTTzy61bKCFtIDwocxDQ1p0EHeuTFgR/+9wrOsdHzMvkmyZQpTowECePVgRlJUoo89V/bs68xBIrIDzga49BYQPZR5mRXTiCrP/tv/ebv/do+eFWYskWsaQJbrR0IVJq92jOF2hOGjNKC5Ro68UbRAUK+B8oCAuIHwo89B4GJ24wuwDAC6HFfD1PQB+BmBV0HFZLrlNyZTESxmlRAdc02vzwADnky4SUSuwIItZ1u2CX/r5URCTgAxk/hYQPhRV5QdbN8QSZtbxOBHApwFcDODEMMdkueQizJIqiVHP41MRhIns0aMfdIUhaGS9+9mMjXnvOzaWT2VoumatRuNBLGh9ISWGxTc6sYWZdQ7sBWCf1hL2uCyWXISZX+DZlCOFmrRZ2Dk4+RWTH1FH2PuJrzy6D0zFtVZjWYsFTQ6k5NB4GI24XZnvBfAbAJN2d+ZGAL8OOi7LpVAWs24+GSKUaD8dFzYWLvv98yVKTEo/8ZVXW+5VXFnWYpLUhx4hpBT4CbMw8cg+AOA1qjqsqr+nqstU9fciROSoJl7xx9yEDTQ0MgJMTgJzc9Zfn9g3fvGMwiQJYKyrvGk9bhHv7c4YZn7xykKEwEsFd3EFzPfCshYSv4xSBaamGLOQJA5jjxWTMMLsIVhBZYkTd6A9E6YIokBXb4VfQFJ3kmo1YNGi9v2yaLhJOMIEifUTX1FjGXdNQDkdH7e0gxsRljVfnPm6fTswMOC/PyPKlp8CKaFm09L6U1PU/oXDZEprLQAOgxXL7HIAn2stQcdlueQWLsNJN078XXhLJjhWgORM2CIQ+AzTfMghEunXC0cMeOXrokULQ6hL0DfcVuxq27RRW8WKxo+Cechn5QrBNsgbxI1jBuAzAM4FsLK1BB2X5ZKJMAsqXWFeuigh332S0W1jzhekeMR+JmlX9nHmcq0bzkmCM63gmRoY9LrKQ/K6fWkL9kzjDh4Kkw0F06KFIq4wuyNon7yX1IVZt2qoFdNAxPoSXrTI+02I+FZ0oxEXLbJimvEFqRhpV/Yham9Wvl0QJnJwgTM1cJq4AonIRDE8l8bYTcFarWBRWONUHWGLZ8G0aKGIK8w+AWAUwP7o1XAZfrEATCopzNw7fiU2xOeIaZewozP5gmREmqbKtCv7KDNT1GmNDU2YfC1wphqLHWZzFxyp4vHcGlihg7IjWEMXTKXE0f5hb6VgWrRQxBVmGz2W3gmX4RcLoFWSvUp2FHXkPjbEG+O3S9h4ZnxBMqAAXY2xKLjlprSY8tVpZS+YGHPSsxYzj8q1jo3hXsECvkvdav+wgqtgWrRQxBJmZVhSFWbdCCy/6J/uxWuSxJh+PbSYFQjTwzBNjhmVNCp7vy75AouF0uGVzwVruE2U1ccsthHS430WzIb/6C2wFTQKxvantq3t/hpjN5WlSGdOV8IMwJvsv2/3WkzH5bGkKsyimJ+cb2ScALQhPkeC5ix0vwxeYw34gqRLo2FZEDwnnk9TSBVN6JFwlMy8ULZRmYkUbY+T1GUq/GOriDDzzMtFu7QxcE5Hg9TACq33b1LBXJlvOXG6FWYfs/9e7bFcZTouj6WQFrNGo9Pbvq8v3IziMSxm/f2dIzC9xh2IqB5/fCXqiEISaFEoauNbMnFQKbp1yInb2FdELASRWNF25Vdoq1DFPno6ik1tlX+7WOJ7TQN2ZcYhqhO/00/MrYYWLQpXMLv0MTOVf1OF5G4H+N4kRygfHK/Gt9FoH2xSq2X7UOitmx/ddHvHbewrJhb8SLNoh9K2Vf/oCdO7VJV7TYCuhRmAVwL4RwD/aS8XA3iF3zF5LJmEy3C+daZRmi1zlWp3L6HbzBVgXWs0woVDi9Iby/cmGcKMWmtgxUJXZ/8mbYzd5B1SZWAgu4ay6o1HkQnzERhllvsw9NDzTv1Wg9RZhT56PG81TO9SCe81LbrtyjwKwBYAHwNwKoA/sf9/BMDrTcflsWQe+T/MV2bUl7DLL9cwl4nSG8v3Jhl8nWMHB60h9tje/rhlR/5dnT1kQSkkzhYvzldX2Be5QmIhiFSLdpj4Zv2bvN/vkolgYz6O3RT8YVGye02TboXZdwAc57H+jQC+YzoujyWXKZmCvo6ifp51OXovbDgk9/tiqo/53iSDX57Xa9u01rfVO/+DujqzSnwP+BwVnjhfXbSYeZJo0Q4Q0Z7xzdx+piX86PF102j19Hg1MiW81zTpVpg96LPtAdO2PJZCzJXpJurnWZj+Ro/jw16mxCPzS4sznF3Y7uS2AJ090FASH7r96qKPWfqE6HY2xjfr31Tqj55ANw2nnzU/8Ix0K8w2+Gy73bQtj6WQwkw1WsEM29/o0UB3W/753mRDpLhymOxcmaWPGSkO3X51cVRm+oR4qQPjm5U030MNbOKHZCDdCrPHAHzOY7kUwKOm4/JYCivMohB29GdAl1ZJ3/VKE9ZaNu+nkeeozJiw/CUMM7SYhHipfeObldhSGSoUkGsuXRbhTroVZiv9FtNxeSyVEGaq0R1/PQ4v6bteaUxfmLVatSoslr8SwlazO0L4BHvFN1u0yB5sbwo6XRJL03yxCbgP1glmGMesjHRRorPy42VdHo3EKqeCZ3yP+ZGXH7aa3RMy79wRkNwxx/0sTaUgIB9YJ5ihMCsr9lvdwJmhprTIYuQ76/LuiK2pSpDxPRR5oRqw1YxHxJe6sr5ZPvnAOsEMhVmZcBXyKJPAZlHPBl2j0Si1i1T2hK3cS9CIliCJ1Saq+mermSmhRzNWCNYJZijM8iBMJRkihkWUCXKzMKoETZ7uNtUD4Wei6jmiPLASNKIlMOpVl24yn61mpvhazLp0TSi4dwPrBB+6df7/N8f//+Da9n3TcXkshRFmfoGr3KUxZNTXwCHXhiSk8qI2Glrv32Ssy/1GkLOu9yBKw1iSRrToDUVl6aZ8eNVBAwOBU8GR7oglUjxerLKIHtYJ3nQrzO5w/H+7aVsRlkJE/veK2OpXSYYMbmUMUlj3TFW692uaSsiuDPxGkBfIsFMcoljBylILk3zo1qLq9k53z9XKMpYoXYkUw7tfr20rRtvQBRRr3Quz273+9/qd91KIuTLDBKtyVpIhg1sZ51TMuiA7hGTH5NuNjl1KWVlkTlQrB2szYiIJi2pJrLI9h+G5RO1NKQr8xrToVpjdD+AwAIcDuM/+/w9av03H5bFkLsyihHKPajHzEGxtQggbtYEzs71f1VBf5CYfM8AyKPYMYQUUayiSFEmUpRL4MfYkhudS1imfqP8tuhVmPwbwI9NiOi6PJXNhFjaUu18laapIx8ZiBZlNDb+3ySFEGrVVuscLnu3YbT6wYnHri2SI2kCWzQpmSm/Z7qOK+D2DMM+HLWYxMTyXRm1VcAT+An7oUf9bcFRm0oS1drV+hx2V6d6nSBYVPyEZciRpEW4jdYreuMURUBHKQHUfcAkJW48Uqb4hC/g8l7bXuX9TZwT+ItU9NkWvIrOiW4vZ//FbTMflsRTCxwxQXbw4ebNQkSwRXmnxeMtMvg898SLG/BxMe1RtrIbXVKMWybJLOvF7brR85ksUt4eg/TI0RaXxfddrRa1bYfZNj+UGAJMAZk3H5bHkNirTGUk1qIRVtcLzqAxMvg+VNl0bRGoUkZJ6hRX3UzVqF36lHnCJCfPcerFlzJukX/iMTFFJJLuqzWEUEunKBHA0gO8AuBXA28Iel8WSWxyzsC9CUEkucyn1yIMGVuig7AhsC7w+2EuJyYIasdZKvV6N+0XdhcWszEW7MoQdrEQLZ7Yk/cJnZIpiV2QyxBJmAI53DAQ4MWj/PJbchFnYhi7Icb7Mdl1X+htYYfuYzc23116T91bqgz3IUhbyxnyLUxIKJ26NGtHHLMp0YiRFgj4cnAWNSjo7uvlQCuOXnPLzi/t9xyJm0W1X5lsB3GJbyY4x7VeEJRcfsyjdVn4luWSxrDwvb69s4MwOS1mrIXYeVzmXpIR8O4xFobYtGfGeZh+Ex3p+WReIMC9grVbuj8Sy0U3dX4Dn08177WwyOybFkR1WCKgeU2ndCrM5ANMO37K2xXRcHkumwqybbiu/kpxE9HdniI0UC3dQveCnVWu1hXERfh/spSQhBWLM39qq5BROhsKew+ILiqkO6+tLrpyRYKIKrSiuMym+41GTHcZgW8fG4BNVjG6F2Rv9FtNxeSyZCrNuuq38SnKURj1smI64hds9sKFWC2UB6Sa8WyXq/wS/ZD3r1DQUTgYCjRazAmMavEQlnS1R3sMw9UBGVrUoyQ7j4iiY7bkKIinn/wE7+v9+YY/JaslUmCUxJ527CyjsixRF+cRxIHXPlweoDgyoYM731sP6GHstpf9QSlPolNRJuCA9L8QEBwWUizD1QAG/hsI0W/MWsx76EOjWYvZFAAfZ/78IwL0A7gHwMIAVpuPyWAphMYtT8MM26lGUT7eF2+ca9f5N3re++Amjj1mYZJbZtSCTnsGSDqtXzd0lkngR5CNLJV1MwtQDSVjXE35pg4pax2wFPfIh0K0w+4Xj/78EcL39/0sA3GE6Lo8ldx+zrCovr2ubXsRuC7fP500DZ+rgol2+L5VzVGbVP8S7LQpd1XvdVpZexyXVNUrVVT7COPxUJo5NBQl659IaeR2jHJibrTmty1Thp5BKi26F2R2O//8TwDle24qw5DYq0/lyZNVIua+T9HQ4AT50jdoq14TqHlOAwHset6p9iHc7OikzXW+6mMm3KIpSZj9lsTHVR4HmCz7DUjM2Fn1qQCcpWdONzWMPf9x1K8x+BOCPbb+y3wJ4ib1+NwD3m47LY8ktjlkLP0tWFoUtycLt42Pma23xsL44k+UclVmV968bw1Poei+JZ2q6WBJhEQroy0Js/ESz3/tblRezVwljDQ16zzmUOjO6FWavAPBdAHe6rGV/BOAfTcflseQuzKr2FWoYlamqdBh20I02CVXvJWWN8rtYXOHHCry4+BVMCurqkkTdzPKRGYmMyizykrswCzXspJ5vGpMiia+yitCNfgpV7yVVOaZZybICLy5Bgpxd0NUkQm+GkYzLRw/3ZPoKsz5EQERuj7J/zzA0FLzP9HT66ciCkRFgzRqgXgdErL9jY+2/16yx9qs4XlkRdOsTE8DgYPu6QezAxPYLgGbTWmEqK1HLkOfFBq31cfE696JFwPbtQF8fMDy8cD8kW0z10dDQQqGt1RbW77578DmbTeuZ8tkWlzDtUNB+3VRqXdJsAqOjwNSUpQCnpqzfLFqIZjFDwZz+W0vuFrNQoY3r+aaRFIZGQ7Ve29Y5gKKboMOhLlZP55PU7UTonhCVlph8CLJ6RLWK0MpWbJx1RpDVLOi5ZWjC6nWjO5LqygTw8Sj7Z7XkLsxU/V8OVmLEjV+tVMaGsNdr2aLh18BGfVZ8tsUlaOBZlOn6Mq53et1NNZYwA/APYdbluRRCmDnp5Y7zXifssw+qlcpWhnq9li0TUZ8Vn21ueFYDzpWmCem7Ec0ZC/Be1/t+wiyMj9mJHuvekkg/alUZGQEmJ4G5OetvD/hbEURzmvDzAwJil6HMXYKC7ocUh6jPis82Fzyrk3OeRfOsby+snJ31Prgbn+akfFtDkqYLbNkxCjMRGRORewC8UkTudiwbAdydXRIJKQnj48DMTPu6mRlrvZuTT7aca50kVCt5Vuhn7UBzyQXpKTTWsuUh6rPis80Fz+rk+RdgHCHyvRvRnLEAz3CcQfkwmdJgzY85DOA6AHXHso/pmLyWwnVlkt4kbNwwL0d5EcsfJAGMXQTYmK6vWtm6X3uZqM+KzzZzjNUJZr03xPUL85o1oOi+rSUGPl2ZYm0vN8uXL9f169fnnQzS6wwPW+YpN7UasHNn5+evm3rd6raMSV+fVau6EcxhDv2JXYcUgGbTMq1MT1uWjYkJmhwqgqk6qWMSk1jWvrK/33J7CFsG3OXm5JOBtWvb6ygR4H3vAz7/+dj3QjoRkQ2qutxrW6Q4ZoQQH0xdPkCwKAMS8+Uw9khgOtHrkJxoORCKAGefzUBQFcUY8xAXta8UsURVWH9UL1+HL36xs45SBb797dj3QaJDYUZIUpicJp58MtzxCflyBFbodNouL85GFeg0jZp8GtNIBwPOpkpHdVLbjjUD52ME1y3s1LJqRbGSejmvmXrO+BGXC4UTZiKyWkQeFpE77eXkvNNEiBPfNslrNGUYIZSgM/V8hV7bDsEc6pjEGrzHqtDptF1uvBpVN1NT6QomhmzPjLbq5InFGLn6hPYPv2uvjd7VGEVs8SMuH0zOZ3ktAFYD+ECUY+j8T7LCMwYjtmujtipa5PRFi6xBAGk7U+fttJ339atG2PkQ4zpvdxOgtr+fz7cMmJ4fHf8zBWWaxJzCjBSZrkc8FkmgZJWWMs5gUHRMBdBviRqxM+i5+YlDPt9ciPRKm55vlFkCSGzKKMwmYcVKuwrA7xj2GwWwHsD6oaGhFLKNkE5CDWEvcqWWpVjq9dDeaeA3BY9piRqhP+i5BYlDPt9M6eqVLtKHYgAlSmokCifMAPwQwM89llMBvBhAPyz/twkAVwWdjxYzkhW+FrMyWA6yFEt+gqGIeVMWTC1VUs82zHRhbiUQRwiSWFTp+8ddtMfGqmt09xNmhY5jJiLDAL6lqq/x249xzEhWtPyenf7Xg9ix4FzvpIjxwoxBzsTyME4SUyAmwBqEwDDfyeJZOLvIZ2MALUd5bjaBlSu9pwQqYrmvMFm+0mniVXxNVKGIlSqOmYjs7/j5p7AsaYQUAt8Rj26KONQ8y2lXvOJ2tMgqrEMvkdQcN2GmYBoZsWJncaqm3KnKVKZhBhy3KGLVmiSFE2YAPiUi94jI3QD+EMBf5Z0gQpyMjFhD1+ca12ESy7xFGVDMmjHLeQ9bQsFE1WvXPPAK19LNOcIIPE52WAgyeaUziFvHKB4OTH2cZVroY0Zyw2/oeVEdIbL2pq2SEwwhBSTVVzrq6IIuExN2wDF9zEoCfcxIbng5RnCOuXaS8n0ihGRPGJ/DFjHe9TA+ZvV6daaDLZWPGSGlwqs7p5to3FWGXV6ElBdTH6PXei9HsZkZNC+8LbAntFVN1Gqd2wYHgUaj+975skGLGSGEEEK8iWIx8xgi2sQKjOIKzGCP+XVeRrRm09J109PAPvtY65580vInq4qVzAktZoQQQgiJTpTRBR5e+eP4RJsoAzoHZbunX926Fdi50+p86BUrmRMKM0IIIYR4E8UVwUPETcN7CKWzJ9TQA9qzEXV2yzsBhBBCCCkwIyPhzFatfVp9kkNDGNo+g6mtizt2dRrXorix9QK0mBFCCCEkGVyx9CYuWRzYE1qVILlJQWFGCCGEkFQI0xOaZdzrMsCuTEIIIYSkRlBPqEcPaCVHYoaFFjNCCCGE5EpbD+hEEyPjw6lOAVVkaDEjhBBCSDFwTwEwNWX9BnrGhEaLGSFxyWCCX0II6QkYO4PCjJBYuCMjtr7uKM4IISQ6IWNnVPl7mMKMkDjw644QQuLTUlqmaSIdsTOq/j1MYUZIHBgZkRBC4uFUWl6bB87B8Pafz1vHLryw2t/DFGaExIGREQkhvUbS/YhePQ+tS9VWYVSuwNTWxfPWsa1bvU9Tle9hCjNC4sDIiISQXiKNfkSTohLB+OLPYea5cAEkqvI9TGFGSByiTPBLSFmosmc1iUcafrU+PQ9hrWBV+h6mMCMkLq654SjKSKmpumc1iUcafrU+PQ8mzVarVfd7mMKMEELIAhxpTPxIw6/Wp+fBS7MNDFh/qzp9E4UZIYSQBTjSmPiRll+toefBrdlqNevv1q0ug+55N1em+53CjBBCyAIcaUz8yMGv1qnZFi8GnnuuffvMDDD+xaHKdL+LmoK5lYjly5fr+vXr804GIYSUH/dchYBlEamSEw8pLX193jFoBXOYQ3/7ynrdUnQFREQ2qOpyr220mBFCCFmAI41Jt6Q1mtdx3qG+zZ67DMGjq72k3e/hgoMQQgjpHUZGKMRINNyW1lZ3IhCvLLnOOzH7IYziCsxgj/ldBmUGE3pR57El7X6nxYwQQggh8fAbzRvHkuY67wiuwxq8B/X+zQsG3ffdjpHBb7QfV+LAZhRmhBBCvGk20VxyAYZlEn0yh+El29vaVMahJfOYug1blrNuHfM9zjuC6zA5N7QwgPPzx1Sq+53O/4QQQjppNtE894cY3XVZe7fRouex5irLC4ZjBMg8w8Pek5D39wOzs53rwzrmm85bYMf+MND5nxBCSDQuvBDjuz7aJsoAYOa53TA+zji0xIUpvpmXKAPCO+a7ztvECgzLFPqmNmJ4GDjvvAWr7ZIl1lJ2Cy6FGSGEkHaaTWDrVkzD23l6eppxaIkL02jeet17fz/HfGcf+fg4sHIlUK+jiTMxKv+CKR2CQjA1BXzhCwu9pFu3egSeLaE4Y1cmIYSQduzuo2FsxBSGOza32toK9jCRpIkaF89n/+HxEc8y50dRyyO7MgkhhITHNntN4CIMYkfbpsFFz2NiIr2ZeUhJCDvyI2pcPJ8+8m6ssWW04DKOGSGEkHaGrOltRnAdAGAcn8A0hjDU9zAmrjqwrU0dH6/uZNLEQNSYZVHi4vn0kdvFMhJlDGVGixkhhJB2HOawEVyHSSzD3OCemLzmp23tq2HeaVJ10hz54VJSTazAMDaiT5/H9u3AwED4U5XVgkthRgghpB1Oy0T8SHPkh+OjoIkVGMUVmMIwFH3YutUqjrXaQrEcG1soprVa+7ayFlkKM0IIIZ3QHEZMmPoHu+k3dPuqAfMfBeP4REe4lueeAxYvXiiWRx+9sG3xYuCSS8pfZCnMCCGEEBKepEZ+tHzV3LMCAMDkJKZl2POwqamFuGXnntv9pAJFhcKMEEIIIeFJqqs7wFfNzwDXilu2a5f34WWeLoxxzAghhBCSPX19lsJyIwLMzXmGNAvL4GCxpwtjHDNCCCGEFIsAXzW3YS4s/f3lni6MwowQQggh2RPCV805BsU0u5P78LjTc+YNhRkhhBBCsieir5qXjlu0qDNERjfTcxYJRv4nhBBCSD5EmBWgtVuY2Sa8ptssS7BZWswIIYQQUgpaXZvXXmv9Pvvs9lGXzebCYM/+fmtd2YLN0mJGCCGEkNJgmqpz3Tpg7dqF9bOzC5aysogygOEyCCGEEFIihoe9JzPv7/d2/K/XLStbkWC4DEIIIYQUnxCRYU2jK8s+GrMFhRkhhBBC8sc0RZNLnJlGV7Z8ytyUZTRmCwozQgghhORPwBRNLUzhz0ZHk5nCM28ozAghhBCSP6Y+R9f6VvizWm1h3e67t/8FrO2t0ZhlmjuTozIJIYQQkj9DQ95e/Ya+yJ07F/7fuhX4whe8t5tGcQLFHK1JixkhhBBC8ifEFE0tvHo93bR6QUP2kBYGCjNCCCGE5E+EKZrCjrScng7dQ1oY2JVJCCGEkGIQcoomU6+n135ApB7S3KHFjBBCCCGlwqvX083goucxsf0CTEyNYFDa+zKLPFqTwowQQgghpcKr13NszPG7th1r9D0Y2XopRvCvWKlXoR/PA1D09wMrVxbT8R/glEyEEEIIqRqOeZuaWIFRXIEZ7DG/eXAw34nNOSUTIYQQQnoHh2f/OD7RJsoAjsokhBBCCMkOh2f/NLy9/Is6KpPCjBBCCCHVwjE6YAjeCoyjMgkhhBBCUqBjyiWMoLnyexju34QpDEEw17Z/kUdlMo4ZIYQQQkqL15RL7343oHoMds1a6xTWaE1Va+TmxERxR2XmYjETkdNE5BciMiciy13bPiIivxKRB0Tkj/JIHyGEEELKgdeUS889B+za1b6uJcomJ4sryoD8LGY/B/B2AJc7V4rIqwGcAeAgAL8L4Ici8gpVnc0+iYQQQggpOlGc+Ivq8O8kF4uZqt6nqg94bDoVwJdV9VlV3QjgVwCOyDZ1hBBCCCkLUZz4i+rw76Rozv8HANjk+L3ZXteBiIyKyHoRWf/4449nkjhCCCGEFAuv6Zn6+zv3K7LDv5PUhJmI/FBEfu6xnJrE+VV1jaouV9Xl++67bxKnJIQQQkjJcE/PVKt1CjORYk/D5CQ1HzNVPaGLwx4GcKDj91J7HSGEEEKIJyMjC6JreBjYurV9uyrw7W9nnqyuKFpX5g0AzhCRF4jIMgAvB/DfOaeJEEIIISXB5OBfBsd/IL9wGX8qIpsBHAXgP0XkewCgqr8A8G8A7gXwXQB/wRGZhBBCCAmLycG/DI7/QH6jMv9DVZeq6gtU9cWq+keObROq+lJVfaWqfieP9BFCCCGknHgNBiiL4z9QvK5MQgghhJCucQ8GqNet32Vw/AcozAghhBBSMUZGrAj/c3Pekf475tZsZp9GExRmhBBCCOkZWnNrTk1ZozWnpoCzzgKWLCmGQKMwI4QQQkjP4DW3JmCF2BgdzV+cUZgRQgghpGfwC5sxM2MJtzyhMCOEEEJIzxAUNiPveGcUZoQQQgjpGbzCaTjJO94ZhRkhhBBCeoZWOI099vDefvLJ2abHDYUZIYQQQqqNKz7GCJpYssR717zn1KQwI4QQQkh18YqPMTqK6Sn13J0+ZoQQQgghaeEVH2NmBkP9D3vuTh8zQgghhJC0MJjAJmb/upBzalKYEUIIIaS6GExgI/V1hZxTk8KMEEIIIdXFNMzy5JMD59TMAwozQgghhFQX0zBL9/qCzGy+Wy5XJYQQQgjJAtMwS+f61sjN1iABe+QmgMzNaLSYEUIIIaS6mIZZOtcbRm7mMXEmhRkhhBBCqovXHEzu4ZdhrGoZQWFGCCGEkOrSmoPJb/hlGKtaRlCYEUIIIaTaBA2/DGNVywgKM0IIIYT0NmGsahnBUZmEEEIIISMjhQhkRosZIYQQQkhBoDAjhBBCCCkIFGaEEEIIIQWBwowQQgghpCBQmBFCCCGEFAQKM0IIIYSQgkBhRgghhBBSECjMCCGEEEIKAoUZIYQQQkhBoDAjhBBCCCkIoqp5pyE2IvI4gKm809HjLAHwRN6JIIHwOZUDPqdywOdUDor4nOqquq/XhkoIM5I/IrJeVZfnnQ7iD59TOeBzKgd8TuWgbM+JXZmEEEIIIQWBwowQQgghpCBQmJGkWJN3Akgo+JzKAZ9TOeBzKgelek70MSOEEEIIKQi0mBFCCCGEFAQKMxIbEXm/iKiILLF/i4h8TkR+JSJ3i8gf5J3GXkZEPi0i99vP4j9EZG/Hto/Yz+kBEfmjHJNJAIjISfaz+JWIfDjv9BALETlQRH4kIveKyC9E5EJ7/T4i8gMR+aX993fyTisBRKRfRO4QkW/Zv5eJyG32e/UVEVmUdxr9oDAjsRCRAwG8GcC0Y/VbALzcXkYBfCGHpJEFfgDgNap6MIAHAXwEAETk1QDOAHAQgJMAfF5E+nNLZY9j5/0/w3p/Xg1ghf2MSP48D+D9qvpqAK8H8Bf2s/kwgBtV9eUAbrR/k/y5EMB9jt//AOCzqvoyAP8L4M9zSVVIKMxIXD4L4EMAnM6KpwK4Ri1uBbC3iOyfS+oIVPX7qvq8/fNWAEvt/08F8GVVfVZVNwL4FYAj8kgjAWDl/a9U9deq+hyAL8N6RiRnVHWLqt5u/78NVqN/AKzns9bebS2AP8klgWQeEVkK4K0A/sX+LQDeBOBr9i6Ff04UZqRrRORUAA+r6l2uTQcA2OT4vdleR/Ln3QC+Y//P51Qs+DxKgIgMAzgMwG0AXqyqW+xNvwHw4rzSReb5J1jGgjn7dw3Abx0fp4V/r3bLOwGk2IjIDwG8xGPTOICLYHVjkpzxe06q+g17n3FYXTLNLNNGSFUQkcUA/h3AX6rq05YxxkJVVUQY5iBHROSPATymqhtE5Lick9M1FGbEF1U9wWu9iLwWwDIAd9mV01IAt4vIEQAeBnCgY/el9jqSEqbn1EJEzgHwxwCO14UYOXxOxYLPo8CIyAAsUdZU1a/bqx8Vkf1VdYvtrvFYfikkAI4GcIqInAzghQD2AnAJLHea3WyrWeHfK3Zlkq5Q1XtUdT9VHVbVYVjm4T9Q1d8AuAHAu+zRma8H8JTD3E8yRkROgmXaP0VVZxybbgBwhoi8QESWwRqs8d95pJEAAP4HwMvtEWSLYA3MuCHnNBHM+yldCeA+Vf2MY9MNAFba/68E8I2s00YWUNWPqOpSu006A8B/qeoIgB8BeKe9W+GfEy1mJA2+DeBkWM7kMwDOzTc5Pc9lAF4A4Ae2dfNWVX2fqv5CRP4NwL2wujj/QlVnc0xnT6Oqz4vI+QC+B6AfwFWq+ouck0UsjgZwNoB7ROROe91FAP4ewL+JyJ8DmALwZ/kkjwTw1wC+LCIfB3AHLJFdWBj5nxBCCCGkILArkxBCCCGkIFCYEUIIIYQUBAozQgghhJCCQGFGCCGEEFIQKMwIIYQQQgoChRkhJHVEZG8ROc9n+ytF5McicqeI3Ccia+z1x4mIisjbHPt+qxXV2z7mAfu4O0Xkax7nPkdEHheRO0TklyLyPRF5g2P734mIb4DeNBCRU0QkkUmvReQqEXlMRH6exPkIIflBYUYIyYK9ARiFGYDPAfisqh6qqq8CcKlj22ZYU4CZGLGPO1RV32nY5yuqepiqvhxW7Kmvi8irAEBV/1ZVfxj6ThJCVW9Q1b9P6HRfAnBSQucihOQIhRkhJAv+HsBLbavWpz227w9LgAGwZpZwbLsLwFMicmISCVHVHwFYA2AUAETkSyLyTvv/SRH5pJ3O9SLyB7aF7SEReV/rHCLyQRH5HxG5W0Q+Zq8btq19V4jIL0Tk+yKyu73tAhG5197/y/a6c0TkMsex/2Vvv1FEhhxp+5yI3CIiv26l0+OefgrgySTyhxCSLxRmhJAs+DCAh2yr1gc9tn8WwH+JyHdE5K9EZG/X9gkAf2M4d9PRlekl+ry4HcDvG7ZNq+qhAG6CZYl6J4DXA2gJsDfDmr7qCACHAjhcRP6PfezLAfyzqh4E4LcA3mGv/zCAw1T1YADzAs/BpQDW2tubsCyILfYHcAysuU6TsrARQgoKp2QihOSOql4tIt+D1R13KoD3isghju0/FRGIyDEeh4+o6vqIlxSfba35Ke8BsFhVtwHYJiLP2oLxzfZyh73fYliCbBrARlW9016/AcCw/f/dsATk9QCu97jmUQDebv9/LYBPObZdr6pzAO4VkReHuDdCSImhxYwQkjkiMtGycrXWqeojqnqVqp4Ka+7O17gO87OaReUwAPcZtj1r/51z/N/6vRssUfdJh1/by1T1StexADCLhY/ftwL4ZwB/AOB/RCTKR7HznH6CkhBSASjMCCFZsA3Anq0fqjreEjYAICIniciA/f9LANQAPOw8gap+H8DvADg4TkJE5I2w/Muu6PIU3wPwbhFZbJ/vABHZz+d6fQAOtH3b/hrAi2BZ2ZzcAuAM+/8RWN2ohJAehF2ZhJDUUdWtIrLODufwHQ8/szcDuEREnrF/f1BVfyMibj+wCQDfcK1rishO+/8nVNUr9MXpdjfoIICNAN6hqiaLWdC9fN8e0fkzEQGA7QDOgmUh86IfQENEXgTL4vU5Vf2tfWyLVQCuFpEPAngcwLlR0iQi1wE4DsASEdkM4KMOKx4hpESIquadBkIIIYQQAnZlEkIIIYQUBgozQgghhJCCQGFGCCGEEFIQKMwIIYQQQgoChRkhhBBCSEGgMCOEEEIIKQgUZoQQQgghBYHCjBBCCCGkIPw/CkOlXgBhcSsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# t_SNE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 유클리드 거리 계산 함수 정의\n",
    "def calculate_euclidean_distances(client_file, dictionary_file):\n",
    "    # 변환된 파일을 읽어옵니다.\n",
    "    client_data = pd.read_csv(client_file)\n",
    "    dictionary_data = pd.read_csv(dictionary_file)\n",
    "    \n",
    "    # 데이터 포인트 간의 유클리드 거리를 계산합니다.\n",
    "    distances = euclidean_distances(client_data.values, dictionary_data.values)\n",
    "    \n",
    "    # top@1 score를 뺀 후 4차원 벡터화\n",
    "    top1_scores = distances[:, 0]\n",
    "    top5_scores = np.sort(distances, axis=1)[:, :5]\n",
    "    top5_minus_top1 = top5_scores - top1_scores[:, np.newaxis]\n",
    "    \n",
    "    return top5_minus_top1\n",
    "\n",
    "# 변환된 파일 경로\n",
    "dictionary_file = \"Dictionary_smashed_data.csv\"\n",
    "\n",
    "# t-SNE를 위한 4차원 벡터 계산\n",
    "vectors_list = []\n",
    "for i in range(5, 6):\n",
    "    client_file = f'Client_smashed_data_epoch{i}.csv'\n",
    "    vectors = calculate_euclidean_distances(client_file, dictionary_file)\n",
    "    print(vectors)\n",
    "    vectors_list.append(vectors)\n",
    "\n",
    "# 리스트를 배열로 변환\n",
    "vectors_array = np.concatenate(vectors_list, axis=0)\n",
    "\n",
    "# t-SNE를 적용하여 2차원으로 축소\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "transformed_vectors = tsne.fit_transform(vectors_array)\n",
    "\n",
    "# 첫 번째부터 250번째 벡터까지 빨간색, 이후는 파란색으로 점을 찍어 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(transformed_vectors[:250, 0], transformed_vectors[:250, 1], color='red', label='Leaked')\n",
    "plt.scatter(transformed_vectors[250:, 0], transformed_vectors[250:, 1], color='blue', label='Not leaked')\n",
    "plt.title('t-SNE Visualization of 4-Dimensional Vectors')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d26b838f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 5)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adcacd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
